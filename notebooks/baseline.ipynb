{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836d1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152347/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simplified-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikita/ML/work_repo/vtb_competition/vtb_data_fusion_contest\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pyhocon import ConfigFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD_ID = 1\n",
    "\n",
    "fold_id_test = FOLD_ID\n",
    "\n",
    "folds_count = len(glob('data/train_matching_*.csv'))\n",
    "folds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "under-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold_id_valid = np.random.choice([i for i in range(folds_count) if i != fold_id_test], size=1)[0]\n",
    "fold_id_valid = fold_id_test\n",
    "fold_id_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confidential-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14651, 2930, 2930]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matching_train = pd.concat([pd.read_csv(f'data/train_matching_{i}.csv')\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)\n",
    "                              ])\n",
    "df_matching_valid = pd.read_csv(f'data/train_matching_{fold_id_valid}.csv')\n",
    "df_matching_test = pd.read_csv(f'data/train_matching_{fold_id_test}.csv')\n",
    "\n",
    "[len(df) for df in [df_matching_train, df_matching_valid, df_matching_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51e930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5175ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_types(df):\n",
    "    df['hour'] = df['timestamp'].apply(lambda x: int(x[11:13]))\n",
    "    return df\n",
    "\n",
    "def click_pivot(df):\n",
    "    catid_pivot = df.pivot_table(index = 'user_id', \n",
    "                            values=['timestamp'],\n",
    "                            columns=['cat_id'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "    catid_pivot.columns = [f'click_catid_{str(i[0])}_{str(i[2])}' for i in catid_pivot.columns]\n",
    "\n",
    "    hour_pivot = df.pivot_table(index = 'user_id', \n",
    "                            values=['timestamp'],\n",
    "                            columns=['hour'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "    hour_pivot.columns = [f'click_hour_{str(i[0])}_{str(i[2])}' for i in hour_pivot.columns]\n",
    "    clickstream_embed = pd.concat([catid_pivot, hour_pivot], axis=1)\n",
    "\n",
    "    clickstream_embed.loc['0'] = np.empty(len(clickstream_embed.columns))\n",
    "\n",
    "    dtype_clickstream = list()\n",
    "    for x in clickstream_embed.dtypes.tolist():\n",
    "        if x=='int64':\n",
    "            dtype_clickstream.append('int16')\n",
    "        elif(x=='float64'):\n",
    "            dtype_clickstream.append('float32')\n",
    "        else:\n",
    "            dtype_clickstream.append('object')\n",
    "\n",
    "    dtype_clickstream = dict(zip(clickstream_embed.columns.tolist(), dtype_clickstream))\n",
    "    clickstream_embed = clickstream_embed.astype(dtype_clickstream)\n",
    "    clickstream_embed.reset_index(drop=False, inplace=True)\n",
    "    return clickstream_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd058cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 7.89 s, total: 1min 21s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_click = pd.read_csv(f'data/clickstream.csv', usecols=[0,1,2])\n",
    "df_click = click_types(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cdf0b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 6.4 s, total: 40.9 s\n",
      "Wall time: 41 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152347/3318947284.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clickstream_embed.reset_index(drop=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_click = click_pivot(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eae0746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12227, 427) (2446, 427) (2446, 427)\n"
     ]
    }
   ],
   "source": [
    "df_click_train = df_click[lambda x: x['user_id'].isin(df_matching_train['rtk'].values)]\n",
    "df_click_valid = df_click[lambda x: x['user_id'].isin(df_matching_valid['rtk'].values)]\n",
    "df_click_test = df_click[lambda x: x['user_id'].isin(df_matching_test['rtk'].values)]\n",
    "\n",
    "print(df_click_train.shape, df_click_valid.shape, df_click_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac890524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bc6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trx_types(df):\n",
    "    df['mcc_code'] = df['mcc_code'].astype(str)\n",
    "    df['currency_rk'] = df['currency_rk'].astype(str)\n",
    "    df['hour'] = pd.to_datetime(df['transaction_dttm']).dt.hour\n",
    "    return df[['user_id', 'mcc_code', 'currency_rk', 'transaction_amt', 'hour']]\n",
    "\n",
    "def trx_pivot(df):\n",
    "    mcc_pivot = df.pivot_table(index = 'user_id', \n",
    "                            values=['transaction_amt'],\n",
    "                            columns=['mcc_code'],\n",
    "                            aggfunc=['sum','mean', 'count']).fillna(0)\n",
    "    mcc_pivot.columns = [f'trx_mmc_{str(i[0])}_{str(i[2])}' for i in mcc_pivot.columns]\n",
    "\n",
    "    hour_pivot = df.pivot_table(index = 'user_id', \n",
    "                            values=['transaction_amt'],\n",
    "                            columns=['hour'],\n",
    "                            aggfunc=['sum','mean', 'count']).fillna(0)\n",
    "    hour_pivot.columns = [f'trx_hour_{str(i[0])}_{str(i[2])}' for i in hour_pivot.columns]\n",
    "    bankclient_embed = pd.concat([mcc_pivot, hour_pivot], axis=1)\n",
    "\n",
    "    dtype_bankclient = list()\n",
    "    for x in bankclient_embed.dtypes.tolist():\n",
    "        if x=='int64':\n",
    "            dtype_bankclient.append('int16')\n",
    "        elif(x=='float64'):\n",
    "            dtype_bankclient.append('float32')\n",
    "        else:\n",
    "            dtype_bankclient.append('object')\n",
    "    \n",
    "    dtype_bankclient = dict(zip(bankclient_embed.columns.tolist(), dtype_bankclient))\n",
    "    bankclient_embed = bankclient_embed.astype(dtype_bankclient)\n",
    "    bankclient_embed.reset_index(drop=False, inplace=True)\n",
    "    return bankclient_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef414e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152347/3185118963.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  bankclient_embed.reset_index(drop=False, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14651, 1231) (2930, 1231) (2930, 1231)\n",
      "CPU times: user 31.3 s, sys: 4.84 s, total: 36.2 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_trx = pd.read_csv(f'data/transactions.csv')\n",
    "df_trx = trx_types(df_trx)\n",
    "df_trx = trx_pivot(df_trx)\n",
    "\n",
    "df_trx_train = df_trx[lambda x: x['user_id'].isin(df_matching_train['bank'].values)]\n",
    "df_trx_valid = df_trx[lambda x: x['user_id'].isin(df_matching_valid['bank'].values)]\n",
    "df_trx_test = df_trx[lambda x: x['user_id'].isin(df_matching_test['bank'].values)]\n",
    "\n",
    "print(df_trx_train.shape, df_trx_valid.shape, df_trx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ca5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb238769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85481, 1659), (17095, 1659))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_dataset(df_matching, df_trx, df_click, neg_count=19):\n",
    "    positive = df_matching[df_matching['rtk'] != '0']\n",
    "    positive = pd.merge(positive, df_trx, left_on='bank', right_on='user_id').drop(columns='user_id')\n",
    "    positive = pd.merge(positive, df_click, left_on='rtk', right_on='user_id').drop(columns='user_id')\n",
    "    positive['target'] = 1\n",
    "    \n",
    "    rtks = df_click['user_id'].unique()\n",
    "\n",
    "    negative = pd.DataFrame(data=df_trx['user_id'].values, columns=['bank'])\n",
    "    negative['rtk'] = negative['bank'].apply(lambda x: np.random.choice(rtks, size=neg_count))\n",
    "    negative = negative.explode('rtk')\n",
    "\n",
    "    negative = pd.merge(negative, df_trx, left_on='bank', right_on='user_id').drop(columns='user_id')\n",
    "    negative = pd.merge(negative, df_click, left_on='rtk', right_on='user_id').drop(columns='user_id')\n",
    "    negative['target'] = 0\n",
    "\n",
    "    dataset = pd.concat([positive, negative]).sample(frac=1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train = prepare_dataset(df_matching_train, df_trx_train, df_click_train, neg_count=5)\n",
    "valid = prepare_dataset(df_matching_valid, df_trx_valid, df_click_valid, neg_count=5)\n",
    "\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "156c3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "drop_columns = ['bank', 'rtk', 'target']\n",
    "TARGET = 'target'\n",
    "CAT_FEATURES = []\n",
    "\n",
    "params = dict(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    n_estimators=5000,\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.75,\n",
    "    subsample_freq=1,\n",
    "    feature_fraction=0.75,\n",
    "    max_depth=8,\n",
    "    lambda_l1=0.5,\n",
    "    lambda_l2=0.5,\n",
    "    num_leaves=128,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2083dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/.local/share/virtualenvs/pytorch-lifestream-VR0LSEAW/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/nikita/.local/share/virtualenvs/pytorch-lifestream-VR0LSEAW/lib/python3.8/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttraining's auc: 0.963008\tvalid_1's auc: 0.778249\n",
      "[500]\ttraining's auc: 0.991752\tvalid_1's auc: 0.795655\n",
      "[750]\ttraining's auc: 0.998323\tvalid_1's auc: 0.802749\n",
      "[1000]\ttraining's auc: 0.999738\tvalid_1's auc: 0.807344\n",
      "[1250]\ttraining's auc: 0.999972\tvalid_1's auc: 0.809115\n",
      "[1500]\ttraining's auc: 0.999998\tvalid_1's auc: 0.811108\n",
      "[1750]\ttraining's auc: 1\tvalid_1's auc: 0.814084\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.815527\n",
      "[2250]\ttraining's auc: 1\tvalid_1's auc: 0.81665\n",
      "[2500]\ttraining's auc: 1\tvalid_1's auc: 0.818465\n",
      "[2750]\ttraining's auc: 1\tvalid_1's auc: 0.82007\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.820656\n",
      "[3250]\ttraining's auc: 1\tvalid_1's auc: 0.82203\n",
      "[3500]\ttraining's auc: 1\tvalid_1's auc: 0.823272\n",
      "[3750]\ttraining's auc: 1\tvalid_1's auc: 0.823484\n",
      "[4000]\ttraining's auc: 1\tvalid_1's auc: 0.823938\n",
      "[4250]\ttraining's auc: 1\tvalid_1's auc: 0.824894\n",
      "[4500]\ttraining's auc: 1\tvalid_1's auc: 0.825687\n",
      "[4750]\ttraining's auc: 1\tvalid_1's auc: 0.826166\n",
      "[5000]\ttraining's auc: 1\tvalid_1's auc: 0.826229\n",
      "0.8262\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(train.drop(columns=drop_columns),\n",
    "                                 label=train[TARGET],\n",
    "                                 categorical_feature=CAT_FEATURES)\n",
    "\n",
    "valid_data = lgb.Dataset(valid.drop(columns=drop_columns),\n",
    "                         label=valid[TARGET],\n",
    "                         categorical_feature=CAT_FEATURES)\n",
    "\n",
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=250)\n",
    "preds = lgb_model.predict(valid.drop(columns=drop_columns))\n",
    "\n",
    "metric_value = roc_auc_score(valid[TARGET], preds)\n",
    "    \n",
    "print(round(metric_value, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6c8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75fc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_valid.set_index('user_id', inplace=True)\n",
    "df_click_valid.set_index('user_id', inplace=True)\n",
    "df_matching_valid.set_index('bank', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(df_trx, df_click, model, model_features, batch_size=200):\n",
    "\n",
    "    list_of_rtk = list(df_click.index.unique())\n",
    "    list_of_rtk = [x for x in list_of_rtk if x != '0']\n",
    "    list_of_bank = list(df_trx.index.unique())\n",
    "\n",
    "    submission = pd.DataFrame(list_of_bank, columns=['bank'])\n",
    "    submission['rtk'] = submission['bank'].apply(lambda x: list_of_rtk)\n",
    "\n",
    "    num_of_batches = int((len(list_of_bank))/batch_size)+1\n",
    "    submission_ready = []\n",
    "\n",
    "    for i in range(num_of_batches):\n",
    "        bank_ids = list_of_bank[(i*batch_size):((i+1)*batch_size)]\n",
    "        if len(bank_ids) != 0:\n",
    "            part_of_submit = submission[submission['bank'].isin(bank_ids)].explode('rtk')\n",
    "            part_of_submit = part_of_submit.merge(df_trx, how='left', left_on='bank', right_index=True\n",
    "                                        ).merge(df_click, how='left', left_on='rtk', right_index=True).fillna(0)\n",
    "\n",
    "            for feature in model_features:\n",
    "                if feature not in part_of_submit.columns:\n",
    "                    part_of_submit[feature] = 0\n",
    "\n",
    "            part_of_submit['predicts'] = model.predict(part_of_submit[model_features])\n",
    "            part_of_submit = part_of_submit[['bank', 'rtk', 'predicts']]\n",
    "            \n",
    "            zeros_part = pd.DataFrame(bank_ids, columns=['bank'])\n",
    "            zeros_part['rtk'] = 0\n",
    "            zeros_part['predicts'] = 1.0\n",
    "            part_of_submit = pd.concat((part_of_submit, zeros_part))\n",
    "\n",
    "            part_of_submit = part_of_submit.sort_values(by=['bank', 'predicts'], ascending=False).reset_index(drop=True)\n",
    "            part_of_submit = part_of_submit.pivot_table(index='bank', values='rtk', aggfunc=list)\n",
    "            part_of_submit['rtk'] = part_of_submit['rtk'].apply(lambda x: x[:100])\n",
    "            part_of_submit['bank'] = part_of_submit.index\n",
    "            part_of_submit = part_of_submit[['bank', 'rtk']]\n",
    "            submission_ready.extend(part_of_submit.values)\n",
    "\n",
    "    submission_final = np.array(submission_ready, dtype=object)\n",
    "    return submission_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f111a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "preds = inference(df_trx_valid, df_click_valid, lgb_model, lgb_model.feature_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f48926",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def score(preds, matching):\n",
    "    pre = 0.0\n",
    "    mrr = 0.0\n",
    "\n",
    "    for ix_bank, pred in preds:\n",
    "        pred = [str(x) for x in pred]\n",
    "        match = matching.loc[ix_bank]['rtk']\n",
    "        d = match in pred\n",
    "        if d:\n",
    "            pre += 1\n",
    "            mrr += 1 / (1 + pred.index(match))\n",
    "\n",
    "    pre /= len(preds)\n",
    "    mrr /= len(preds)\n",
    "    r1 = 2 * pre * mrr / (pre + mrr)\n",
    "\n",
    "    return pre, mrr, r1\n",
    "\n",
    "pre, mrr, r1 = score(preds, df_matching_valid)\n",
    "\n",
    "print(f'pre: {pre:.4f}, mrr: {mrr:.4f}, r1: {r1:.4f}')\n",
    "\n",
    "# pre: 0.4242, mrr: 0.1888, r1: 0.2613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016634c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('lgb_submit/lgb_model.p', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da6576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f615a3",
   "metadata": {},
   "source": [
    "### Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca13ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_test.set_index('bank', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(preds, matching):\n",
    "    pre = 0.0\n",
    "    mrr = 0.0\n",
    "\n",
    "    for ix_bank, pred in preds:\n",
    "        pred = [str(x) for x in pred]\n",
    "        match = matching.loc[ix_bank]['rtk']\n",
    "        d = match in pred\n",
    "        if d:\n",
    "            pre += 1\n",
    "            mrr += 1 / (1 + pred.index(match))\n",
    "\n",
    "    pre /= len(preds)\n",
    "    mrr /= len(preds)\n",
    "    \n",
    "    r1 = 2 * pre * mrr / (pre + mrr)\n",
    "\n",
    "    return pre, mrr, r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('data/test/submission.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "pre, mrr, r1 = score(preds, df_matching_test)\n",
    "\n",
    "print(f'pre: {pre:.4f}, mrr: {mrr:.4f}, r1: {r1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a45e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
