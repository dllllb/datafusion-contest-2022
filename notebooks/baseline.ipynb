{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836d1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_317547/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simplified-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikita/ML/work_repo/vtb_competition/vtb_data_fusion_contest\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "restricted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pyhocon import ConfigFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD_ID = 1\n",
    "\n",
    "fold_id_test = FOLD_ID\n",
    "\n",
    "folds_count = len(glob('data/train_matching_*.csv'))\n",
    "folds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "under-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold_id_valid = np.random.choice([i for i in range(folds_count) if i != fold_id_test], size=1)[0]\n",
    "fold_id_valid = fold_id_test\n",
    "fold_id_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confidential-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14651, 2930, 2930]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matching_train = pd.concat([pd.read_csv(f'data/train_matching_{i}.csv')\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_matching_valid = pd.read_csv(f'data/train_matching_{fold_id_valid}.csv')\n",
    "df_matching_test = pd.read_csv(f'data/train_matching_{fold_id_test}.csv')\n",
    "\n",
    "[len(df) for df in [df_matching_train, df_matching_valid, df_matching_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-experiment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5175ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_types(df):\n",
    "    df['cat_id'] = df['cat_id'].astype(str)\n",
    "    return df[['user_id', 'timestamp', 'cat_id']]\n",
    "\n",
    "def click_pivot(df):\n",
    "    clickstream_embed = df.pivot_table(index = 'user_id', \n",
    "                            values=['timestamp'],\n",
    "                            columns=['cat_id'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "    clickstream_embed.columns = [f'{str(i[0])}-{str(i[2])}' for i in clickstream_embed.columns]\n",
    "    clickstream_embed.loc['0'] = np.empty(len(clickstream_embed.columns))\n",
    "\n",
    "    dtype_clickstream = list()\n",
    "    for x in clickstream_embed.dtypes.tolist():\n",
    "        if x=='int64':\n",
    "            dtype_clickstream.append('int16')\n",
    "        elif(x=='float64'):\n",
    "            dtype_clickstream.append('float32')\n",
    "        else:\n",
    "            dtype_clickstream.append('object')\n",
    "\n",
    "    dtype_clickstream = dict(zip(clickstream_embed.columns.tolist(), dtype_clickstream))\n",
    "    clickstream_embed = clickstream_embed.astype(dtype_clickstream)\n",
    "    clickstream_embed.reset_index(drop=False, inplace=True)\n",
    "    return clickstream_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3dc0d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 16.7 s, total: 1min 57s\n",
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58744/1841381636.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clickstream_embed.reset_index(drop=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_click = pd.read_csv(f'data/clickstream.csv')\n",
    "df_click = click_types(df_click)\n",
    "df_click = click_pivot(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adb4a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12227, 403) (2446, 403) (2446, 403)\n"
     ]
    }
   ],
   "source": [
    "df_click_train = df_click[lambda x: x['user_id'].isin(df_matching_train['rtk'].values)]\n",
    "df_click_valid = df_click[lambda x: x['user_id'].isin(df_matching_valid['rtk'].values)]\n",
    "df_click_test = df_click[lambda x: x['user_id'].isin(df_matching_test['rtk'].values)]\n",
    "\n",
    "print(df_click_train.shape, df_click_valid.shape, df_click_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2815fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac890524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20bc6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trx_types(df):\n",
    "    df['mcc_code'] = df['mcc_code'].astype(str)\n",
    "    df['currency_rk'] = df['currency_rk'].astype(str)\n",
    "    df['event_time'] = pd.to_datetime(df['transaction_dttm']).astype(int) / 1e9\n",
    "    return df[['user_id', 'event_time', 'mcc_code', 'currency_rk', 'transaction_amt']]\n",
    "\n",
    "def trx_pivot(df):\n",
    "    bankclient_embed = df.pivot_table(index = 'user_id', \n",
    "                        values=['transaction_amt'],\n",
    "                        columns=['mcc_code'],\n",
    "                        aggfunc=['sum','mean', 'count']).fillna(0)\n",
    "    bankclient_embed.columns = [f'{str(i[0])}-{str(i[2])}' for i in bankclient_embed.columns]\n",
    "    \n",
    "    dtype_bankclient = list()\n",
    "    for x in bankclient_embed.dtypes.tolist():\n",
    "        if x=='int64':\n",
    "            dtype_bankclient.append('int16')\n",
    "        elif(x=='float64'):\n",
    "            dtype_bankclient.append('float32')\n",
    "        else:\n",
    "            dtype_bankclient.append('object')\n",
    "    \n",
    "    dtype_bankclient = dict(zip(bankclient_embed.columns.tolist(), dtype_bankclient))\n",
    "    bankclient_embed = bankclient_embed.astype(dtype_bankclient)\n",
    "    bankclient_embed.reset_index(drop=False, inplace=True)\n",
    "    return bankclient_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ef414e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58744/3274736351.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  bankclient_embed.reset_index(drop=False, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14651, 1159) (2930, 1159) (2930, 1159)\n",
      "CPU times: user 28.1 s, sys: 3.68 s, total: 31.8 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_trx = pd.read_csv(f'data/transactions.csv')\n",
    "df_trx = trx_types(df_trx)\n",
    "df_trx = trx_pivot(df_trx)\n",
    "\n",
    "df_trx_train = df_trx[lambda x: x['user_id'].isin(df_matching_train['bank'].values)]\n",
    "df_trx_valid = df_trx[lambda x: x['user_id'].isin(df_matching_valid['bank'].values)]\n",
    "df_trx_test = df_trx[lambda x: x['user_id'].isin(df_matching_test['bank'].values)]\n",
    "\n",
    "print(df_trx_train.shape, df_trx_valid.shape, df_trx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb238769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((293020, 1563), (58600, 1563))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_dataset(df_matching, df_trx, df_click, neg_count=19):\n",
    "    positive = pd.merge(df_matching, df_trx, left_on='bank', right_on='user_id').drop(columns='user_id')\n",
    "    positive = pd.merge(positive, df_click, left_on='rtk', right_on='user_id').drop(columns='user_id')\n",
    "    positive['target'] = 1\n",
    "\n",
    "    rtks = df_click['user_id'].unique()\n",
    "\n",
    "    negative = pd.DataFrame(data=df_trx['user_id'].values, columns=['bank'])\n",
    "    negative['rtk'] = negative['bank'].apply(lambda x: np.random.choice(rtks, size=neg_count))\n",
    "    negative = negative.explode('rtk')\n",
    "\n",
    "    negative = pd.merge(negative, df_trx, left_on='bank', right_on='user_id').drop(columns='user_id')\n",
    "    negative = pd.merge(negative, df_click, left_on='rtk', right_on='user_id').drop(columns='user_id')\n",
    "    negative['target'] = 0\n",
    "\n",
    "    dataset = pd.concat([positive, negative]).sample(frac=1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train = prepare_dataset(df_matching_train, df_trx_train, df_click_train)\n",
    "valid = prepare_dataset(df_matching_valid, df_trx_valid, df_click_valid)\n",
    "\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8086f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1aec26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac2a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/.local/share/virtualenvs/pytorch-lifestream-VR0LSEAW/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/nikita/.local/share/virtualenvs/pytorch-lifestream-VR0LSEAW/lib/python3.8/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's auc: 0.802914\tvalid_1's auc: 0.693215\n",
      "[100]\ttraining's auc: 0.825306\tvalid_1's auc: 0.702917\n",
      "[150]\ttraining's auc: 0.848137\tvalid_1's auc: 0.712487\n",
      "[200]\ttraining's auc: 0.862664\tvalid_1's auc: 0.720189\n",
      "[250]\ttraining's auc: 0.874733\tvalid_1's auc: 0.727031\n",
      "[300]\ttraining's auc: 0.885656\tvalid_1's auc: 0.734197\n",
      "[350]\ttraining's auc: 0.895889\tvalid_1's auc: 0.739423\n",
      "[400]\ttraining's auc: 0.906407\tvalid_1's auc: 0.743545\n",
      "[450]\ttraining's auc: 0.916071\tvalid_1's auc: 0.748621\n",
      "[500]\ttraining's auc: 0.923991\tvalid_1's auc: 0.75215\n",
      "[550]\ttraining's auc: 0.931653\tvalid_1's auc: 0.755164\n",
      "[600]\ttraining's auc: 0.938567\tvalid_1's auc: 0.758097\n",
      "[650]\ttraining's auc: 0.944226\tvalid_1's auc: 0.760724\n",
      "[700]\ttraining's auc: 0.950255\tvalid_1's auc: 0.76339\n",
      "[750]\ttraining's auc: 0.954702\tvalid_1's auc: 0.765855\n",
      "[800]\ttraining's auc: 0.95908\tvalid_1's auc: 0.768386\n",
      "[850]\ttraining's auc: 0.962288\tvalid_1's auc: 0.770328\n",
      "[900]\ttraining's auc: 0.965467\tvalid_1's auc: 0.772169\n",
      "[950]\ttraining's auc: 0.968447\tvalid_1's auc: 0.773961\n",
      "[1000]\ttraining's auc: 0.971101\tvalid_1's auc: 0.775936\n",
      "[1050]\ttraining's auc: 0.973309\tvalid_1's auc: 0.777268\n",
      "[1100]\ttraining's auc: 0.975577\tvalid_1's auc: 0.77842\n",
      "[1150]\ttraining's auc: 0.977481\tvalid_1's auc: 0.779969\n",
      "[1200]\ttraining's auc: 0.979275\tvalid_1's auc: 0.781432\n",
      "[1250]\ttraining's auc: 0.980918\tvalid_1's auc: 0.782647\n",
      "[1300]\ttraining's auc: 0.982352\tvalid_1's auc: 0.783901\n",
      "[1350]\ttraining's auc: 0.983665\tvalid_1's auc: 0.785146\n",
      "[1400]\ttraining's auc: 0.984831\tvalid_1's auc: 0.786018\n",
      "[1450]\ttraining's auc: 0.985986\tvalid_1's auc: 0.786797\n",
      "[1500]\ttraining's auc: 0.987018\tvalid_1's auc: 0.787691\n",
      "[1550]\ttraining's auc: 0.987943\tvalid_1's auc: 0.788536\n",
      "[1600]\ttraining's auc: 0.988811\tvalid_1's auc: 0.789495\n",
      "[1650]\ttraining's auc: 0.989607\tvalid_1's auc: 0.789742\n",
      "[1700]\ttraining's auc: 0.990357\tvalid_1's auc: 0.79007\n",
      "[1750]\ttraining's auc: 0.991068\tvalid_1's auc: 0.790569\n",
      "[1800]\ttraining's auc: 0.99169\tvalid_1's auc: 0.791149\n",
      "[1850]\ttraining's auc: 0.992193\tvalid_1's auc: 0.791801\n",
      "[1900]\ttraining's auc: 0.99271\tvalid_1's auc: 0.792346\n",
      "[1950]\ttraining's auc: 0.993266\tvalid_1's auc: 0.793253\n",
      "[2000]\ttraining's auc: 0.993672\tvalid_1's auc: 0.79348\n",
      "[2050]\ttraining's auc: 0.994053\tvalid_1's auc: 0.794113\n",
      "[2100]\ttraining's auc: 0.994377\tvalid_1's auc: 0.794339\n",
      "[2150]\ttraining's auc: 0.994715\tvalid_1's auc: 0.794584\n",
      "[2200]\ttraining's auc: 0.995046\tvalid_1's auc: 0.795073\n",
      "[2250]\ttraining's auc: 0.995403\tvalid_1's auc: 0.795319\n",
      "[2300]\ttraining's auc: 0.995692\tvalid_1's auc: 0.795926\n",
      "[2350]\ttraining's auc: 0.995972\tvalid_1's auc: 0.796346\n",
      "[2400]\ttraining's auc: 0.996193\tvalid_1's auc: 0.796626\n",
      "[2450]\ttraining's auc: 0.996438\tvalid_1's auc: 0.796765\n",
      "[2500]\ttraining's auc: 0.996645\tvalid_1's auc: 0.796842\n",
      "[2550]\ttraining's auc: 0.996874\tvalid_1's auc: 0.797225\n",
      "[2600]\ttraining's auc: 0.997051\tvalid_1's auc: 0.797536\n",
      "[2650]\ttraining's auc: 0.997237\tvalid_1's auc: 0.797912\n",
      "[2700]\ttraining's auc: 0.997421\tvalid_1's auc: 0.798217\n",
      "[2750]\ttraining's auc: 0.997568\tvalid_1's auc: 0.798431\n",
      "[2800]\ttraining's auc: 0.997724\tvalid_1's auc: 0.798523\n",
      "[2850]\ttraining's auc: 0.997873\tvalid_1's auc: 0.798742\n",
      "[2900]\ttraining's auc: 0.997987\tvalid_1's auc: 0.799127\n",
      "[2950]\ttraining's auc: 0.998106\tvalid_1's auc: 0.799412\n",
      "[3000]\ttraining's auc: 0.998229\tvalid_1's auc: 0.799603\n",
      "[3050]\ttraining's auc: 0.998339\tvalid_1's auc: 0.799746\n",
      "[3100]\ttraining's auc: 0.998433\tvalid_1's auc: 0.799901\n",
      "[3150]\ttraining's auc: 0.998531\tvalid_1's auc: 0.799979\n",
      "[3200]\ttraining's auc: 0.998623\tvalid_1's auc: 0.800281\n",
      "[3250]\ttraining's auc: 0.998705\tvalid_1's auc: 0.80058\n",
      "[3300]\ttraining's auc: 0.998774\tvalid_1's auc: 0.800632\n",
      "[3350]\ttraining's auc: 0.99885\tvalid_1's auc: 0.800529\n",
      "[3400]\ttraining's auc: 0.998917\tvalid_1's auc: 0.800825\n",
      "[3450]\ttraining's auc: 0.998981\tvalid_1's auc: 0.800789\n",
      "[3500]\ttraining's auc: 0.999036\tvalid_1's auc: 0.800778\n",
      "[3550]\ttraining's auc: 0.999086\tvalid_1's auc: 0.800666\n",
      "[3600]\ttraining's auc: 0.999137\tvalid_1's auc: 0.800677\n",
      "[3650]\ttraining's auc: 0.999183\tvalid_1's auc: 0.800959\n",
      "[3700]\ttraining's auc: 0.999235\tvalid_1's auc: 0.801001\n",
      "[3750]\ttraining's auc: 0.999274\tvalid_1's auc: 0.80101\n",
      "[3800]\ttraining's auc: 0.999314\tvalid_1's auc: 0.801186\n",
      "[3850]\ttraining's auc: 0.999353\tvalid_1's auc: 0.801322\n",
      "[3900]\ttraining's auc: 0.999387\tvalid_1's auc: 0.801266\n",
      "[3950]\ttraining's auc: 0.999422\tvalid_1's auc: 0.801185\n",
      "[4000]\ttraining's auc: 0.99945\tvalid_1's auc: 0.80119\n",
      "[4050]\ttraining's auc: 0.999475\tvalid_1's auc: 0.801137\n",
      "[4100]\ttraining's auc: 0.999504\tvalid_1's auc: 0.801143\n",
      "[4150]\ttraining's auc: 0.99953\tvalid_1's auc: 0.801154\n",
      "[4200]\ttraining's auc: 0.999555\tvalid_1's auc: 0.800952\n",
      "[4250]\ttraining's auc: 0.999579\tvalid_1's auc: 0.801127\n",
      "[4300]\ttraining's auc: 0.999601\tvalid_1's auc: 0.801311\n",
      "[4350]\ttraining's auc: 0.99962\tvalid_1's auc: 0.801574\n",
      "[4400]\ttraining's auc: 0.99964\tvalid_1's auc: 0.801603\n",
      "[4450]\ttraining's auc: 0.999661\tvalid_1's auc: 0.801779\n",
      "[4500]\ttraining's auc: 0.999679\tvalid_1's auc: 0.801821\n",
      "[4550]\ttraining's auc: 0.999696\tvalid_1's auc: 0.801911\n",
      "[4600]\ttraining's auc: 0.999709\tvalid_1's auc: 0.80213\n",
      "[4650]\ttraining's auc: 0.999722\tvalid_1's auc: 0.802157\n",
      "[4700]\ttraining's auc: 0.999735\tvalid_1's auc: 0.80226\n",
      "[4750]\ttraining's auc: 0.999746\tvalid_1's auc: 0.802471\n",
      "[4800]\ttraining's auc: 0.999758\tvalid_1's auc: 0.802537\n",
      "[4850]\ttraining's auc: 0.999769\tvalid_1's auc: 0.802511\n",
      "[4900]\ttraining's auc: 0.999779\tvalid_1's auc: 0.802554\n",
      "[4950]\ttraining's auc: 0.999788\tvalid_1's auc: 0.802538\n",
      "[5000]\ttraining's auc: 0.999797\tvalid_1's auc: 0.802582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8026"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "drop_columns = ['bank', 'rtk', 'target']\n",
    "TARGET = 'target'\n",
    "CAT_FEATURES = []\n",
    "\n",
    "params = dict(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    n_estimators=5000,\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.75,\n",
    "    subsample_freq=1,\n",
    "    feature_fraction=0.75,\n",
    "    max_depth=8,\n",
    "    lambda_l1=0.5,\n",
    "    lambda_l2=0.5,\n",
    "    num_leaves=128,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(train.drop(columns=drop_columns),\n",
    "                                 label=train[TARGET],\n",
    "                                 categorical_feature=CAT_FEATURES)\n",
    "\n",
    "valid_data = lgb.Dataset(valid.drop(columns=drop_columns),\n",
    "                         label=valid[TARGET],\n",
    "                         categorical_feature=CAT_FEATURES)\n",
    "\n",
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=50)\n",
    "preds = lgb_model.predict(valid.drop(columns=drop_columns))\n",
    "\n",
    "metric_value = roc_auc_score(valid[TARGET], preds)\n",
    "round(metric_value, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fda5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_valid.set_index('user_id', inplace=True)\n",
    "df_click_valid.set_index('user_id', inplace=True)\n",
    "df_matching_valid.set_index('bank', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "501e0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(df_trx, df_click, model, model_features, batch_size=200):\n",
    "\n",
    "    list_of_rtk = list(df_click.index.unique())\n",
    "    list_of_bank = list(df_trx.index.unique())\n",
    "\n",
    "    submission = pd.DataFrame(list_of_bank, columns=['bank'])\n",
    "    submission['rtk'] = submission['bank'].apply(lambda x: list_of_rtk)\n",
    "\n",
    "    num_of_batches = int((len(list_of_bank))/batch_size)+1\n",
    "    submission_ready = []\n",
    "\n",
    "    for i in range(num_of_batches):\n",
    "        bank_ids = list_of_bank[(i*batch_size):((i+1)*batch_size)]\n",
    "        if len(bank_ids) != 0:\n",
    "            part_of_submit = submission[submission['bank'].isin(bank_ids)].explode('rtk')\n",
    "            part_of_submit = part_of_submit.merge(df_trx, how='left', left_on='bank', right_index=True\n",
    "                                        ).merge(df_click, how='left', left_on='rtk', right_index=True).fillna(0)\n",
    "\n",
    "            for feature in model_features:\n",
    "                if feature not in part_of_submit.columns:\n",
    "                    part_of_submit[feature] = 0\n",
    "\n",
    "            part_of_submit['predicts'] = model.predict(part_of_submit[model_features])\n",
    "            part_of_submit = part_of_submit[['bank', 'rtk', 'predicts']]\n",
    "\n",
    "            part_of_submit = part_of_submit.sort_values(by=['bank', 'predicts'], ascending=False).reset_index(drop=True)\n",
    "            part_of_submit = part_of_submit.pivot_table(index='bank', values='rtk', aggfunc=list)\n",
    "            part_of_submit['rtk'] = part_of_submit['rtk'].apply(lambda x: x[:100])\n",
    "            part_of_submit['bank'] = part_of_submit.index\n",
    "            part_of_submit = part_of_submit[['bank', 'rtk']]\n",
    "            submission_ready.extend(part_of_submit.values)\n",
    "\n",
    "    submission_final = np.array(submission_ready, dtype=object)\n",
    "    return submission_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f111a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 28min 26s, sys: 38.8 s, total: 1h 29min 4s\n",
      "Wall time: 12min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = inference(df_trx_valid, df_click_valid, lgb_model, lgb_model.feature_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f48926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre: 0.375, mrr: 0.175, r1: 0.239\n",
      "CPU times: user 103 ms, sys: 0 ns, total: 103 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def score(preds, matching):\n",
    "    pre = 0.0\n",
    "    mrr = 0.0\n",
    "\n",
    "    for ix_bank, pred in preds:\n",
    "        pred = [str(x) for x in pred]\n",
    "        match = matching.loc[ix_bank]['rtk']\n",
    "        d = match in pred\n",
    "        if d:\n",
    "            pre += 1\n",
    "            mrr += 1 / (1 + pred.index(match))\n",
    "\n",
    "    pre /= len(preds)\n",
    "    mrr /= len(preds)\n",
    "    r1 = 2 * pre * mrr / (pre + mrr)\n",
    "\n",
    "    return pre, mrr, r1\n",
    "\n",
    "pre, mrr, r1 = score(preds, df_matching_valid)\n",
    "\n",
    "print(f'pre: {pre:.3f}, mrr: {mrr:.3f}, r1: {r1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "016634c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('lgb_submit/lgb_model.p', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da6576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78d550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0f615a3",
   "metadata": {},
   "source": [
    "### Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca13ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_test.set_index('bank', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2c2edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(preds, matching):\n",
    "    pre = 0.0\n",
    "    mrr = 0.0\n",
    "\n",
    "    for ix_bank, pred in preds:\n",
    "        pred = [str(x) for x in pred]\n",
    "        match = matching.loc[ix_bank]['rtk']\n",
    "        d = match in pred\n",
    "        if d:\n",
    "            pre += 1\n",
    "            mrr += 1 / (1 + pred.index(match))\n",
    "\n",
    "    pre /= len(preds)\n",
    "    mrr /= len(preds)\n",
    "    \n",
    "    r1 = 2 * pre * mrr / (pre + mrr)\n",
    "\n",
    "    return pre, mrr, r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54fb03c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre: 0.37167, mrr: 0.175, r1: 0.238\n"
     ]
    }
   ],
   "source": [
    "preds = np.load('data/test/submission.npz', allow_pickle=True)['arr_0']\n",
    "\n",
    "pre, mrr, r1 = score(preds, df_matching_test)\n",
    "\n",
    "print(f'pre: {pre:.5f}, mrr: {mrr:.3f}, r1: {r1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b62ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf6f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
