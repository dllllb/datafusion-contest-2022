{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "simplified-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kireev/pycharm-deploy/vtb\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60312c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d326f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "subtle-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriented-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhocon import ConfigFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "outer-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "monthly-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.data_load.iterable_processing.category_size_clip import CategorySizeClip\n",
    "from dltranz.data_load import augmentation_chain\n",
    "from dltranz.data_load.augmentations.seq_len_limit import SeqLenLimit\n",
    "from dltranz.data_load.augmentations.random_slice import RandomSlice\n",
    "\n",
    "from dltranz.seq_encoder import create_encoder\n",
    "\n",
    "from dltranz.metric_learn.sampling_strategies import get_sampling_strategy\n",
    "from dltranz.metric_learn.losses import get_loss\n",
    "\n",
    "from dltranz.tb_interface import get_scalars\n",
    "\n",
    "from dltranz.data_load import padded_collate_wo_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latter-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtb_code.data import PairedDataset, paired_collate_fn, PairedZeroDataset, DropDuplicate\n",
    "from vtb_code.metrics import PrecisionK, MeanReciprocalRankK, ValidationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-ready",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accepted-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "under-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_id_test = FOLD_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifty-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_count = len(glob('data/train_matching_*.csv'))\n",
    "folds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suburban-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold_id_valid = np.random.choice([i for i in range(folds_count) if i != fold_id_test], size=1)[0]\n",
    "fold_id_valid = (fold_id_test + 1) % folds_count\n",
    "fold_id_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "confidential-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_train = pd.concat([pd.read_csv(f'data/train_matching_{i}.csv')\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_matching_valid = pd.read_csv(f'data/train_matching_{fold_id_valid}.csv')\n",
    "df_matching_test = pd.read_csv(f'data/train_matching_{fold_id_test}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "smooth-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11721, 2930, 2930]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(df) for df in [df_matching_train, df_matching_valid, df_matching_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "toxic-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.09 s, sys: 3.42 s, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(f'data/features_f{FOLD_ID}.pickle', 'rb') as f:\n",
    "    (\n",
    "        features_trx_train,\n",
    "        features_trx_valid,\n",
    "        features_trx_test,\n",
    "        features_trx_puzzle,\n",
    "        features_click_train,\n",
    "        features_click_valid,\n",
    "        features_click_test,\n",
    "        features_click_puzzle,\n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b0062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a652e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da05d450",
   "metadata": {},
   "source": [
    "# Preetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d05624d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, seq_len, random_shift):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.random_shift = random_shift\n",
    "        \n",
    "        self.keys = np.sort(np.array(list(data.keys())))\n",
    "        self.ix = []\n",
    "        for i, k in enumerate(self.keys):\n",
    "            v = self.data[k]\n",
    "            et = v['event_time']\n",
    "            for j in range(0, len(et), seq_len // 2):\n",
    "                self.ix.append([i, j])\n",
    "        self.ix = np.array(self.ix)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.ix.shape[0]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        ix = self.ix[item]\n",
    "        v = self.data[self.keys[ix[0]]]\n",
    "        et = v['event_time']\n",
    "        pos = ix[1]\n",
    "        pos = pos + random.randint(-self.random_shift, self.random_shift)\n",
    "        pos = max(pos, 0)\n",
    "        pos = min(pos, len(et) - self.seq_len // 2)\n",
    "        return {k: v[pos: pos + self.seq_len] for k, v in v.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "239cd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_train_trx_features = dict(chain(\n",
    "    features_trx_train.items(),\n",
    "    features_trx_puzzle.items(),\n",
    "))\n",
    "mlm_valid_trx_features = features_trx_test\n",
    "\n",
    "mlm_train_click_features = dict(chain(\n",
    "    features_click_train.items(),\n",
    "    features_click_puzzle.items(),\n",
    "))\n",
    "mlm_valid_click_features = features_click_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dcf2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DropDuplicate('mcc_code', col_new_cnt='c_cnt')\n",
    "mlm_train_trx_features = {k: dd(v) for k, v in mlm_train_trx_features.items()}\n",
    "mlm_valid_trx_features = {k: dd(v) for k, v in mlm_valid_trx_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db29d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DropDuplicate('cat_id', col_new_cnt='c_cnt')\n",
    "mlm_train_click_features = {k: dd(v) for k, v in mlm_train_click_features.items()}\n",
    "mlm_valid_click_features = {k: dd(v) for k, v in mlm_valid_click_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bed1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_mlm_trx = torch.utils.data.DataLoader(\n",
    "    MLMDataset(mlm_train_trx_features, 512, 32),\n",
    "    collate_fn=padded_collate_wo_target,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    batch_size=64,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "valid_dl_mlm_trx = torch.utils.data.DataLoader(\n",
    "    MLMDataset(mlm_valid_trx_features, 512, 32),\n",
    "    collate_fn=padded_collate_wo_target,\n",
    "    shuffle=False,\n",
    "    num_workers=12,\n",
    "    batch_size=16,\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d69ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_mlm_click = torch.utils.data.DataLoader(\n",
    "    MLMDataset(mlm_train_click_features, 512, 32),\n",
    "    collate_fn=padded_collate_wo_target,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    batch_size=64,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "valid_dl_mlm_click = torch.utils.data.DataLoader(\n",
    "    MLMDataset(mlm_valid_click_features, 512, 32),\n",
    "    collate_fn=padded_collate_wo_target,\n",
    "    shuffle=False,\n",
    "    num_workers=12,\n",
    "    batch_size=64,\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d41c68df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(573, 564)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dl_mlm_trx), len(valid_dl_mlm_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42c42fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(814, 3053, 573, 564)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl_mlm_trx), len(train_dl_mlm_click), len(valid_dl_mlm_trx), len(valid_dl_mlm_click), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6159c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52063, 195372, 9160, 36056)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train_dl_mlm_trx.dataset), len(train_dl_mlm_click.dataset), \n",
    " len(valid_dl_mlm_trx.dataset), len(valid_dl_mlm_click.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168da83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bdd76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a177ffea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9679, -0.8048, -0.7571, -0.7250, -0.7015, -0.6823, -0.6679, -0.6557,\n",
       "        -0.6437, -0.6332, -0.6233, -0.6151, -0.6064, -0.5995, -0.5919, -0.5855,\n",
       "        -0.5789, -0.5724, -0.5663, -0.5601, -0.5539, -0.5481, -0.5427, -0.5372,\n",
       "        -0.5321, -0.5266, -0.5211, -0.5158, -0.5103, -0.5052, -0.4999, -0.4963,\n",
       "        -0.4932, -0.4900, -0.4865, -0.4831, -0.4802, -0.4769, -0.4738, -0.4705,\n",
       "        -0.4670, -0.4639, -0.4607, -0.4574, -0.4541, -0.4512, -0.4479, -0.4446,\n",
       "        -0.4414, -0.4385, -0.4352, -0.4318, -0.4285, -0.4253, -0.4221, -0.4190,\n",
       "        -0.4156, -0.4121, -0.4091, -0.4058, -0.4024, -0.3991, -0.3958, -0.3923,\n",
       "        -0.3887, -0.3854, -0.3816, -0.3778, -0.3739, -0.3697, -0.3663, -0.3621,\n",
       "        -0.3575, -0.3537, -0.3486, -0.3431, -0.3375, -0.3312, -0.3255, -0.3183,\n",
       "        -0.3126, -0.3052, -0.2980, -0.2897, -0.2807, -0.2722, -0.2639, -0.2576,\n",
       "        -0.2498, -0.2417, -0.2233, -0.1300,  0.3547,  0.4939,  0.5650,  0.6230,\n",
       "         0.6739,  0.7290,  0.8014,  1.0000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = []\n",
    "for batch in mlm_train_trx_features.values():\n",
    "    v.append(batch['transaction_amt'])\n",
    "v = torch.cat(v)\n",
    "\n",
    "trx_amnt_quantiles = torch.quantile(torch.unique(v), torch.linspace(0, 1, 100))\n",
    "trx_amnt_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f874c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8b98778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.trx_encoder import TrxEncoder, PaddedBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "289c6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtb_code.models import MeanLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mechanical-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrxTransform(torch.nn.Module):\n",
    "    def __init__(self, trx_amnt_quantiles):\n",
    "        super().__init__()\n",
    "        self.trx_amnt_quantiles = torch.nn.Parameter(trx_amnt_quantiles, requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x.payload['transaction_amt_q'] = torch.bucketize(x.payload['transaction_amt'], self.trx_amnt_quantiles) + 1\n",
    "        return x\n",
    "    \n",
    "class CustomClickTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "#         x.payload['cat_id'] = torch.clamp(x.payload['cat_id'], 0, 300)\n",
    "#         x.payload['level_0'] = torch.clamp(x.payload['level_0'], 0, 200)\n",
    "#         x.payload['level_1'] = torch.clamp(x.payload['level_1'], 0, 200)\n",
    "#         x.payload['level_2'] = torch.clamp(x.payload['level_2'], 0, 200)\n",
    "#         x.payload['c_cnt_clamp'] = torch.clamp(x.payload['c_cnt'], 0, 20).int()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "395037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeaturesTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        et = x.payload['event_time'].int()\n",
    "        et_day = et.div(24 * 60 * 60, rounding_mode='floor').int()\n",
    "        x.payload['hour'] = et.div(60 * 60, rounding_mode='floor') % 24 + 1\n",
    "        x.payload['weekday'] = et.div(60 * 60 * 24, rounding_mode='floor') % 7 + 1\n",
    "        x.payload['day_diff'] = torch.clamp(torch.diff(et_day, prepend=et_day[:, :1], dim=1), 0, 14)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1d9e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBLinear(torch.nn.Linear):\n",
    "    def forward(self, x: PaddedBatch):\n",
    "        return PaddedBatch(super().forward(x.payload), x.seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed9272aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBL2Norm(torch.nn.Module):\n",
    "    def __init__(self, beta):    \n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return PaddedBatch(self.beta * x.payload / (x.payload.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5), \n",
    "                           x.seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "952d0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerConfig, LongformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6396ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMPretrainModule(pl.LightningModule):\n",
    "    def __init__(self, trx_amnt_quantiles, params,\n",
    "                 lr, weight_decay,\n",
    "                 max_lr, pct_start, total_steps,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        common_trx_size = params['common_trx_size']\n",
    "        t = TrxEncoder(self.hparams.params['trx_seq.trx_encoder'])\n",
    "        self.seq_encoder_trx = torch.nn.Sequential(\n",
    "            CustomTrxTransform(trx_amnt_quantiles=trx_amnt_quantiles),\n",
    "            DateFeaturesTransform(),\n",
    "            t, PBLinear(t.output_size, common_trx_size),\n",
    "            PBL2Norm(self.hparams.params['mlm.beta']),\n",
    "        )\n",
    "\n",
    "        t = TrxEncoder(self.hparams.params['click_seq.trx_encoder'])\n",
    "        self.seq_encoder_click = torch.nn.Sequential(\n",
    "            CustomClickTransform(),\n",
    "            DateFeaturesTransform(),\n",
    "            t, PBLinear(t.output_size, common_trx_size),\n",
    "            PBL2Norm(self.hparams.params['mlm.beta']),\n",
    "        )\n",
    "            \n",
    "        self.token_mask = torch.nn.Parameter(torch.randn(1, 1, common_trx_size), requires_grad=True)\n",
    "        self.token_cls = torch.nn.Parameter(torch.randn(1, 1, common_trx_size), requires_grad=True)\n",
    "        \n",
    "        self.transf = LongformerModel(\n",
    "            config=LongformerConfig(\n",
    "                hidden_size=common_trx_size,\n",
    "                num_attention_heads=params['transf.nhead'],\n",
    "                intermediate_size=params['transf.dim_feedforward'],\n",
    "                num_hidden_layers=params['transf.num_layers'],\n",
    "                vocab_size=4,\n",
    "                max_position_embeddings=self.hparams.params['transf.max_len'],\n",
    "                attention_window=params['transf.attention_window'],\n",
    "            ),\n",
    "            add_pooling_layer=False,\n",
    "        )\n",
    "        \n",
    "        self.train_mlm_loss = MeanLoss(compute_on_step=False)\n",
    "        self.valid_mlm_loss = MeanLoss(compute_on_step=False)\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer=optim,\n",
    "            max_lr=self.hparams.max_lr,\n",
    "            total_steps=self.hparams.total_steps,\n",
    "            pct_start=self.hparams.pct_start,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=False,\n",
    "            div_factor=25.0,\n",
    "            final_div_factor=10000.0,\n",
    "            three_phase=False,\n",
    "        )\n",
    "        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n",
    "        return [optim], [scheduler]\n",
    "            \n",
    "    def get_mask(self, attention_mask):\n",
    "        return torch.bernoulli(attention_mask.float() * self.hparams.params['mlm.replace_proba']).bool()\n",
    "        \n",
    "    def mask_x(self, x, attention_mask, mask):\n",
    "        shuffled_tokens = x[attention_mask.bool()]\n",
    "        B, T, H = x.size()\n",
    "        ix = torch.multinomial(torch.ones(shuffled_tokens.size(0)), B * T, replacement=True)\n",
    "        shuffled_tokens = shuffled_tokens[ix].view(B, T, H)\n",
    "        \n",
    "        rand = torch.rand(B, T, device=x.device).unsqueeze(2).expand(B, T, H)\n",
    "        replace_to = torch.where(\n",
    "            rand < 0.8,\n",
    "            self.token_mask.expand_as(x),          # [MASK] token 80%\n",
    "            torch.where(\n",
    "                rand < 0.9,\n",
    "                shuffled_tokens,                   # random token 10%\n",
    "                x,                                 # unchanged 10%\n",
    "            )\n",
    "        )\n",
    "        return torch.where(mask.bool().unsqueeze(2).expand_as(x), replace_to, x)\n",
    "            \n",
    "    def forward(self, z: PaddedBatch):\n",
    "        B, T, H = z.payload.size()\n",
    "        device = z.payload.device\n",
    "        \n",
    "        if self.training:\n",
    "            start_pos = np.random.randint(0, self.hparams.params['transf.max_len'] - T - 1, 1)[0]\n",
    "        else:\n",
    "            start_pos = 0\n",
    "\n",
    "        inputs_embeds=z.payload\n",
    "        attention_mask=z.seq_len_mask.float()\n",
    "\n",
    "        inputs_embeds = torch.cat([\n",
    "            self.token_cls.expand(inputs_embeds.size(0), 1, H),\n",
    "            inputs_embeds,\n",
    "        ], dim=1)\n",
    "        attention_mask = torch.cat([\n",
    "            torch.ones(inputs_embeds.size(0), 1, device=device),\n",
    "            attention_mask,\n",
    "        ], dim=1)\n",
    "        position_ids=torch.arange(T + 1, device=z.device).view(1, -1).expand(B, T + 1) + start_pos\n",
    "        global_attention_mask = torch.cat([\n",
    "            torch.ones(inputs_embeds.size(0), 1, device=device),\n",
    "            torch.zeros(inputs_embeds.size(0), inputs_embeds.size(1) - 1, device=device),\n",
    "        ], dim=1)\n",
    "\n",
    "        out = self.transf(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            global_attention_mask=global_attention_mask,\n",
    "        ).last_hidden_state\n",
    "\n",
    "        return PaddedBatch(out, z.seq_lens)\n",
    "        \n",
    "    def get_neg_ix(self, mask):\n",
    "        \"\"\"Sample from predicts, where `mask == True`, without self element.\n",
    "        sample from predicted tokens from batch\n",
    "        \"\"\"\n",
    "        mn = mask.float().view(1, -1) - \\\n",
    "            torch.eye(mask.numel(), device=mask.device)[mask.flatten()]\n",
    "        neg_ix = torch.multinomial(mn, self.hparams.params['mlm.neg_count'])\n",
    "        b_ix = neg_ix.div(mask.size(1), rounding_mode='trunc')\n",
    "        neg_ix = neg_ix % mask.size(1)\n",
    "        return b_ix, neg_ix\n",
    "        \n",
    "    def loss_mlm(self, x: PaddedBatch):\n",
    "        mask = self.get_mask(x.seq_len_mask)\n",
    "        masked_x = self.mask_x(x.payload, x.seq_len_mask, mask)\n",
    "        B, T, H = masked_x.size()\n",
    "        \n",
    "        out = self.forward(PaddedBatch(masked_x, x.seq_lens)).payload[:, 1:]\n",
    "        \n",
    "        target = x.payload[mask].unsqueeze(1)  # N, 1, H\n",
    "        predict = out[mask].unsqueeze(1) # N, 1, H\n",
    "        neg_ix = self.get_neg_ix(mask)\n",
    "        negative = out[neg_ix[0], neg_ix[1]]  # N, nneg, H\n",
    "        out_samples = torch.cat([predict, negative], dim=1)\n",
    "        probas = torch.softmax((target * out_samples).sum(dim=2), dim=1)\n",
    "        loss = -torch.log(probas[:, 0])\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_trx, x_click = batch\n",
    "        \n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # PB: B, T, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # PB: B, T, H\n",
    "        z = PaddedBatch(\n",
    "            torch.cat([z_trx.payload, z_click.payload], dim=0),\n",
    "            torch.cat([z_trx.seq_lens, z_click.seq_lens], dim=0),\n",
    "        )\n",
    "        \n",
    "        loss_mlm = self.loss_mlm(z)\n",
    "        self.train_mlm_loss(loss_mlm)\n",
    "        loss_mlm = loss_mlm.mean()\n",
    "        self.log(f'loss/mlm', loss_mlm)\n",
    "\n",
    "        return loss_mlm\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_trx, x_click = batch\n",
    "        \n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # PB: B, T, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # PB: B, T, H\n",
    "        z = PaddedBatch(\n",
    "            torch.cat([z_trx.payload, z_click.payload], dim=0),\n",
    "            torch.cat([z_trx.seq_lens, z_click.seq_lens], dim=0),\n",
    "        )\n",
    "        \n",
    "        loss_mlm = self.loss_mlm(z)\n",
    "        self.valid_mlm_loss(loss_mlm)\n",
    "\n",
    "    def training_epoch_end(self, _):\n",
    "        self.log(f'metrics/train_mlm', self.train_mlm_loss, prog_bar=False)\n",
    "        \n",
    "    def validation_epoch_end(self, _):\n",
    "        self.log(f'metrics/valid_mlm', self.valid_mlm_loss, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a89e33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_trx = ConfigFactory.parse_string('''\n",
    "    common_trx_size: 256\n",
    "    transf: {\n",
    "        nhead: 2\n",
    "        dim_feedforward: 512\n",
    "        num_layers: 4\n",
    "        attention_window: 32\n",
    "        max_len: 6000\n",
    "    }\n",
    "    mlm: {\n",
    "        replace_proba: 0.11\n",
    "        neg_count: 128\n",
    "        beta: 5\n",
    "    }\n",
    "    trx_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            mcc_code: {in: 350, out: 64},\n",
    "            currency_rk: {in: 10, out: 4}\n",
    "            transaction_amt_q: {in: 110, out: 8}\n",
    "            \n",
    "            hour: {in: 30, out: 16}\n",
    "            weekday: {in: 10, out: 4}\n",
    "            day_diff: {in: 15, out: 8}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            transaction_amt: identity\n",
    "            c_cnt: log\n",
    "          }\n",
    "          was_logified: false\n",
    "          log_scale_factor: 1.0\n",
    "        }\n",
    "    }\n",
    "    click_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            cat_id: {in: 400, out: 64},\n",
    "            level_0: {in: 400, out: 16}\n",
    "            level_1: {in: 400, out: 8}\n",
    "            level_2: {in: 400, out: 4}\n",
    "            \n",
    "            hour: {in: 30, out: 16}\n",
    "            weekday: {in: 10, out: 4}\n",
    "            day_diff: {in: 15, out: 8}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            c_cnt: log\n",
    "          }\n",
    "          was_logified: false\n",
    "          log_scale_factor: 1.0\n",
    "        }\n",
    "    }\n",
    "''')\n",
    "\n",
    "mlm_model = MLMPretrainModule(\n",
    "    trx_amnt_quantiles=trx_amnt_quantiles,\n",
    "    params=config_trx,                     \n",
    "    lr=0.001, weight_decay=0,\n",
    "    max_lr=0.001, pct_start=3000 / 35000, total_steps=35000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930867a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "296ce5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.trainer.supporters import CombinedLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b702285",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  4.860\n",
      "version = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type            | Params\n",
      "------------------------------------------------------\n",
      "0 | seq_encoder_trx   | Sequential      | 51.5 K\n",
      "1 | seq_encoder_click | Sequential      | 68.7 K\n",
      "2 | transf            | LongformerModel | 4.4 M \n",
      "3 | train_mlm_loss    | MeanLoss        | 0     \n",
      "4 | valid_mlm_loss    | MeanLoss        | 0     \n",
      "------------------------------------------------------\n",
      "4.6 M     Trainable params\n",
      "100       Non-trainable params\n",
      "4.6 M     Total params\n",
      "18.226    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9790bcaa7e234c409c0c2fc71a32c76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fec1948c2743e49623976b046bb35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[0],\n",
    "    max_steps=35000,\n",
    "    enable_progress_bar=True,\n",
    "    val_check_interval=700,\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            every_n_train_steps=1000, save_top_k=-1,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "model_version = trainer.logger.version\n",
    "print('baseline:  {:.3f}'.format(np.log(mlm_model.hparams.params['mlm.neg_count'] + 1)))\n",
    "print(f'version = {model_version}')\n",
    "trainer.fit(\n",
    "    mlm_model,\n",
    "    CombinedLoader([train_dl_mlm_trx, train_dl_mlm_click], mode='max_size_cycle'), \n",
    "    CombinedLoader([valid_dl_mlm_trx, valid_dl_mlm_click], mode='max_size_cycle'),\n",
    ")\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d52190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4394fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146538b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82bfc3f4",
   "metadata": {},
   "source": [
    "# Use pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v16: 128 size, 2 layers\n",
    "v32: 256 size, 4 layers\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mlm_model_trx = MLMPretrainModuleTrx.load_from_checkpoint(\n",
    "    'lightning_logs/version_152/checkpoints/epoch=54-step=9999.ckpt')  # 42\n",
    "mlm_model_click = MLMPretrainModuleClick.load_from_checkpoint(\n",
    "    'lightning_logs/version_153/checkpoints/epoch=65-step=9999.ckpt')  # 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca25b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlm_model_trx.freeze()\n",
    "# mlm_model_click.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-hartford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.seq_encoder.utils import NormEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c992ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.trx_encoder import TrxEncoder, PaddedBatch\n",
    "from dltranz.seq_encoder.rnn_encoder import RnnEncoder\n",
    "from dltranz.seq_encoder.utils import LastStepEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b11d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Scorer(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        B, H = x.size()\n",
    "        a, b =x[:, :H // 2], x[:, H // 2:]\n",
    "        return -(a - b).pow(2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2698f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBLayerNorm(torch.nn.LayerNorm):\n",
    "    def forward(self, x: PaddedBatch):\n",
    "        return PaddedBatch(super().forward(x.payload), x.seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedModule(pl.LightningModule):\n",
    "    def __init__(self, params, k,\n",
    "                 lr, weight_decay,\n",
    "                 max_lr, pct_start, total_steps,\n",
    "                 beta, neg_count,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        common_trx_size = mlm_model_trx.hparams.params['common_trx_size']\n",
    "        self.rnn_enc =  torch.nn.Sequential(\n",
    "#             RnnEncoder(common_trx_size, params['rnn']), \n",
    "#             LastStepEncoder(),\n",
    "#             NormEncoder(),\n",
    "        )\n",
    "        self._seq_encoder_trx = torch.nn.Sequential(\n",
    "#             mlm_model_trx.seq_encoder,\n",
    "            mlm_model_trx,\n",
    "            torch.nn.Linear(common_trx_size, 2 * common_trx_size),\n",
    "#             PBLayerNorm(common_trx_size),\n",
    "        )\n",
    "        self._seq_encoder_click = torch.nn.Sequential(\n",
    "#             mlm_model_click.seq_encoder,\n",
    "            mlm_model_click,\n",
    "            torch.nn.Linear(common_trx_size, 2 * common_trx_size),\n",
    "#             PBLayerNorm(common_trx_size),\n",
    "        )\n",
    "#         self.mlm_model_click = mlm_model_click\n",
    "        \n",
    "        self.cls = torch.nn.Sequential(\n",
    "            L2Scorer(),\n",
    "        )\n",
    "\n",
    "        self.train_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.train_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        self.valid_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.valid_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        \n",
    "    def seq_encoder_trx(self, x):\n",
    "        x = self._seq_encoder_trx(x)\n",
    "        return self.rnn_enc(x)\n",
    "    \n",
    "    def seq_encoder_click(self, x_orig):\n",
    "        x = self._seq_encoder_click(x_orig)\n",
    "#         x = PaddedBatch(\n",
    "#             x.payload + self.mlm_model_click.sentence_encoding(x_orig),\n",
    "#             x.seq_lens,\n",
    "#         )\n",
    "        return self.rnn_enc(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer=optim,\n",
    "            max_lr=self.hparams.max_lr,\n",
    "            total_steps=self.hparams.total_steps,\n",
    "            pct_start=self.hparams.pct_start,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=False,\n",
    "            div_factor=25.0,\n",
    "            final_div_factor=10000.0,\n",
    "            three_phase=True,\n",
    "        )\n",
    "        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n",
    "        return [optim], [scheduler]\n",
    "\n",
    "    def loss_fn_p(self, embeddings, labels, ref_emb, ref_labels):\n",
    "        beta = self.hparams.beta\n",
    "        neg_count = self.hparams.neg_count\n",
    "        \n",
    "        pos_ix = (labels.view(-1, 1) == ref_labels.view(1, -1)).nonzero(as_tuple=False)\n",
    "        pos_labels = labels[pos_ix[:, 0]]\n",
    "        neg_w = ((pos_labels.view(-1, 1) != ref_labels.view(1, -1))).float()\n",
    "        neg_ix = torch.multinomial(neg_w, neg_count - 1)\n",
    "        all_ix = torch.cat([pos_ix[:, [1]], neg_ix], dim=1)\n",
    "        logits = -(embeddings[pos_ix[:, [0]]] - ref_emb[all_ix]).pow(2).sum(dim=2)\n",
    "        logits = logits * beta\n",
    "        logs = -torch.log(torch.softmax(logits, dim=1))[:, 0]\n",
    "#         logs = torch.relu(logs + np.log(0.1))\n",
    "        return logs.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # pairs\n",
    "        x_trx, l_trx, m_trx, x_click, l_click, m_click = batch\n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # B, H\n",
    "        loss_pt = self.loss_fn_p(embeddings=z_trx, labels=l_trx, ref_emb=z_click, ref_labels=l_click)\n",
    "        self.log('loss/loss_pt', loss_pt)\n",
    "        \n",
    "        loss_pc = self.loss_fn_p(embeddings=z_click, labels=l_click, ref_emb=z_trx, ref_labels=l_trx)\n",
    "        self.log('loss/loss_pc', loss_pc)\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            out = -(z_trx.unsqueeze(1) - z_click.unsqueeze(0)).pow(2).sum(dim=2)\n",
    "            out = out[m_trx == 0][:, m_click == 0]\n",
    "            T, C = out.size()\n",
    "            assert T == C\n",
    "            n_samples = z_trx.size(0) // (l_trx.max().item() + 1)\n",
    "            for i in range(n_samples):\n",
    "                l2 = out[i::n_samples, i::n_samples]\n",
    "                self.train_precision(l2)\n",
    "                self.train_mrr(l2)\n",
    "        \n",
    "        return loss_pt + 0.1 * loss_pc  #  loss_pc \n",
    "\n",
    "    def training_epoch_end(self, _):\n",
    "        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n",
    "        self.log('train_metrics/mrr', self.train_mrr, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-disaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aff1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    PairedZeroDataset(\n",
    "        pd.concat([df_matching_train, df_matching_test], axis=0)[lambda x: x['rtk'].ne('0')].values,\n",
    "        data=[\n",
    "            dict(chain(features_trx_train.items(), features_trx_test.items())),\n",
    "            dict(chain(features_click_train.items(), features_click_test.items())),\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n",
    "        ],\n",
    "        n_sample=2,\n",
    "    ),\n",
    "    collate_fn=PairedZeroDataset.collate_fn,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=24,\n",
    "    batch_size=batch_size,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# train_dl = torch.utils.data.DataLoader(\n",
    "#     PairedZeroDataset(\n",
    "#         pd.concat([df_matching_train, df_matching_test], axis=0)[lambda x: x['rtk'].ne('0')].values,\n",
    "#         data=[\n",
    "#             dict(chain(features_trx_train.items(), features_trx_test.items())),\n",
    "#             dict(chain(features_click_train.items(), features_click_test.items())),\n",
    "#         ],\n",
    "#         augmentations=[\n",
    "#             augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 512)),  # 1024\n",
    "#             augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 1024)),  # 2048\n",
    "#         ],\n",
    "#         n_sample=2,\n",
    "#     ),\n",
    "#     collate_fn=PairedZeroDataset.collate_fn,\n",
    "#     drop_last=True,\n",
    "#     shuffle=True,\n",
    "#     num_workers=24,\n",
    "#     batch_size=batch_size,\n",
    "#     persistent_workers=True,\n",
    "# )\n",
    "\n",
    "valid_dl_trx = torch.utils.data.DataLoader(\n",
    "    PairedDataset(\n",
    "        np.sort(df_matching_valid['bank'].unique()).reshape(-1, 1), \n",
    "        data=[\n",
    "            features_trx_valid,\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), SeqLenLimit(2000)),  # 2000\n",
    "        ],\n",
    "        n_sample=1,\n",
    "    ),\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=128,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valid_dl_click = torch.utils.data.DataLoader(\n",
    "    PairedDataset(\n",
    "        np.sort(df_matching_valid[lambda x: x['rtk'].ne('0')]['rtk'].unique()).reshape(-1, 1),\n",
    "        data=[\n",
    "            features_click_valid,\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), SeqLenLimit(5000)),  # 5000\n",
    "        ],\n",
    "        n_sample=1,\n",
    "    ),\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=128,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_model = PairedModule(\n",
    "    ConfigFactory.parse_string('''\n",
    "    common_trx_size: 128\n",
    "    rnn: {\n",
    "      type: gru,\n",
    "      hidden_size: 256,\n",
    "      bidir: false,\n",
    "      trainable_starter: static\n",
    "    }\n",
    "'''),                     \n",
    "    k=100 * batch_size // 3000,\n",
    "    lr=0.0022, weight_decay=0,\n",
    "    max_lr=0.0018, pct_start=1100 / 6000, total_steps=6000,\n",
    "    beta=0.2 / 1.4, neg_count=120,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(pl.Callback):\n",
    "    def __init__(self, v_trx, v_click, target, device, device_main, k=100, batch_size=1024):\n",
    "        self.v_trx = v_trx\n",
    "        self.v_click = v_click\n",
    "        self.target = target\n",
    "        self.device = device\n",
    "        self.device_main = device_main\n",
    "        self.k = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        was_traning = False\n",
    "        if pl_module.training:\n",
    "            pl_module.eval()\n",
    "            was_traning = True\n",
    "\n",
    "        pl_module.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            z_trx = []\n",
    "            for ((x_trx, _),) in self.v_trx:\n",
    "                z_trx.append(pl_module.seq_encoder_trx(x_trx.to(self.device)))\n",
    "            z_trx = torch.cat(z_trx, dim=0)\n",
    "            z_click = []\n",
    "            for ((x_click, _),) in self.v_click:\n",
    "                z_click.append(pl_module.seq_encoder_click(x_click.to(self.device)))\n",
    "            z_click = torch.cat(z_click, dim=0)\n",
    "\n",
    "            T = z_trx.size(0)\n",
    "            C = z_click.size(0)\n",
    "            device = z_trx.device\n",
    "            ix_t = torch.arange(T, device=device).view(-1, 1).expand(T, C).flatten()\n",
    "            ix_c = torch.arange(C, device=device).view(1, -1).expand(T, C).flatten()\n",
    "\n",
    "            z_out = []\n",
    "            for i in range(0, len(ix_t), self.batch_size):\n",
    "                z_pairs = torch.cat([\n",
    "                    z_trx[ix_t[i:i + self.batch_size]],\n",
    "                    z_click[ix_c[i:i + self.batch_size]],\n",
    "                ], dim=1)\n",
    "                z_out.append(pl_module.cls(z_pairs).unsqueeze(1))\n",
    "            z_out = torch.cat(z_out, dim=0).view(T, C)\n",
    "\n",
    "            precision, mrr, r1 = self.logits_to_metrics(z_out)\n",
    "\n",
    "            pl_module.log('valid_full_metrics/precision', precision, prog_bar=True)\n",
    "            pl_module.log('valid_full_metrics/mrr', mrr, prog_bar=False)\n",
    "            pl_module.log('valid_full_metrics/r1', r1, prog_bar=False)\n",
    "\n",
    "        pl_module.to(self.device_main)\n",
    "        if was_traning:\n",
    "            pl_module.train()\n",
    "\n",
    "    def logits_to_metrics(self, z_out):\n",
    "        T, C = z_out.size()\n",
    "        z_ranks = torch.zeros_like(z_out)\n",
    "        z_ranks[\n",
    "            torch.arange(T, device=self.device).view(-1, 1).expand(T, C),\n",
    "            torch.argsort(z_out, dim=1, descending=True),\n",
    "        ] = torch.arange(C, device=self.device).float().view(1, -1).expand(T, C) + 1\n",
    "        z_ranks = torch.cat([\n",
    "            torch.ones(T, device=self.device).float().view(-1, 1),\n",
    "            z_ranks + 1,\n",
    "        ], dim=1)\n",
    "        \n",
    "        click_uids = np.concatenate([['0'], self.v_click.dataset.pairs[:, 0]])\n",
    "        true_ranks = z_ranks[\n",
    "            np.arange(T),\n",
    "            np.searchsorted(click_uids,\n",
    "                            self.target.set_index('bank')['rtk'].loc[self.v_trx.dataset.pairs[:, 0]].values)\n",
    "        ]\n",
    "        precision = torch.where(true_ranks <= self.k,\n",
    "                                torch.ones(1, device=self.device), torch.zeros(1, device=self.device)).mean()\n",
    "        mrr = torch.where(true_ranks <= self.k, 1 / true_ranks, torch.zeros(1, device=self.device)).mean()\n",
    "        r1 = 2 * mrr * precision / (mrr + precision)\n",
    "        return precision, mrr, r1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-stamp",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[0],\n",
    "    max_steps=6000,\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            every_n_train_steps=1000, save_top_k=-1,\n",
    "        ),\n",
    "        ValidationCallback(valid_dl_trx, valid_dl_click, df_matching_valid,\n",
    "                           torch.device('cuda:0'), torch.device('cuda:0')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-testimony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.fit(sup_model, train_dl)  # valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b61be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4c60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ee83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0: v78\n",
    "1: v79\n",
    "2: v80\n",
    "3: v81\n",
    "4: v82\n",
    "5: v83\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-evanescence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-subsection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_m = get_scalars('lightning_logs/').set_index('version').loc[[f'version_{i}' for i in [78, 79, 80, 81, 82, 83]]]\n",
    "\n",
    "# df = df_m[lambda x: x['tag'].str.startswith('train_metrics')] \\\n",
    "# .pivot(index='step', columns='tag', values='value')\n",
    "# _, axs = plt.subplots(2, 1, figsize=(16, 15))\n",
    "# for col, ax in zip(df.columns, axs):\n",
    "#     df[col].plot(ax=ax, title=col, grid=True)\n",
    "# plt.show()\n",
    "\n",
    "# df = df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    "# .pivot(index='step', columns='tag', values='value')\n",
    "# _, axs = plt.subplots(3, 1, figsize=(16, 18))\n",
    "# for col, ax in zip(df.columns, axs):\n",
    "#     df[col].plot(ax=ax, title=col, grid=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    ".pivot_table(index='tag', columns='version', values='value', aggfunc=lambda x: x[-1]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    ".pivot_table(index='tag', columns='version', values='value', aggfunc=lambda x: x[-1]).mean(axis=1).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfee29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtb",
   "language": "python",
   "name": "vtb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
