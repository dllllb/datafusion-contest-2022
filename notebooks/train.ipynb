{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "simplified-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/kireev/pycharm-deploy/vtb\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "restricted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subtle-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriented-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latin-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "labeled-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhocon import ConfigFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-upper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accepted-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "under-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_id_test = FOLD_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fifty-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_count = len(glob('data/train_matching_*.csv'))\n",
    "folds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suburban-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold_id_valid = np.random.choice([i for i in range(folds_count) if i != fold_id_test], size=1)[0]\n",
    "fold_id_valid = (fold_id_test + 1) % folds_count\n",
    "fold_id_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confidential-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_train = pd.concat([pd.read_csv(f'data/train_matching_{i}.csv')\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_matching_valid = pd.read_csv(f'data/train_matching_{fold_id_valid}.csv')\n",
    "df_matching_test = pd.read_csv(f'data/train_matching_{fold_id_test}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smooth-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11721, 2930, 2930]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(df) for df in [df_matching_train, df_matching_valid, df_matching_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "related-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trx_types(df):\n",
    "    df['mcc_code'] = df['mcc_code'].astype(str)\n",
    "    df['currency_rk'] = df['currency_rk'].astype(str)\n",
    "    df['event_time'] = pd.to_datetime(df['transaction_dttm']).astype(int) / 1e9\n",
    "    return df[['user_id', 'event_time', 'mcc_code', 'currency_rk', 'transaction_amt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "helpful-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_train = pd.concat([trx_types(pd.read_csv(f'data/transactions_{i}.csv'))\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_trx_valid = trx_types(pd.read_csv(f'data/transactions_{fold_id_valid}.csv'))\n",
    "df_trx_test = trx_types(pd.read_csv(f'data/transactions_{fold_id_test}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raised-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_types(df):\n",
    "    df['event_time'] = pd.to_datetime(df['timestamp']).astype(int) / 1e9\n",
    "    df = pd.merge(df, pd.read_csv('data/click_categories.csv'), on='cat_id')\n",
    "    df['cat_id'] = df['cat_id'].astype(str)\n",
    "    return df[['user_id', 'event_time', 'cat_id', 'level_0', 'level_1', 'level_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "worse-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click_train = pd.concat([click_types(pd.read_csv(f'data/clickstream_{i}.csv'))\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_click_valid = click_types(pd.read_csv(f'data/clickstream_{fold_id_valid}.csv'))\n",
    "df_click_test = click_types(pd.read_csv(f'data/clickstream_{fold_id_test}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "second-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from dltranz.data_preprocessing.base import DataPreprocessor\n",
    "from dltranz.data_preprocessing.util import pd_hist\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class PandasDataPreprocessor(DataPreprocessor):\n",
    "    \"\"\"Data preprocessor based on pandas.DataFrame\n",
    "\n",
    "    During preprocessing it\n",
    "        * transform `cols_event_time` column with date and time\n",
    "        * encodes category columns `cols_category` into ints;\n",
    "        * apply logarithm transformation to `cols_log_norm' columns;\n",
    "        * groups flat data by `col_id`;\n",
    "        * arranges data into list of dicts with features\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col_id : str\n",
    "        name of column with ids\n",
    "    cols_event_time : str,\n",
    "        name of column with time and date\n",
    "    cols_category : list[str],\n",
    "        list of category columns\n",
    "    cols_log_norm : list[str],\n",
    "        list of columns to be logarithmed\n",
    "    time_transformation: str. Default: 'default'.\n",
    "        type of transformation to be applied to time column\n",
    "    print_dataset_info : bool. Default: False.\n",
    "        If True, print dataset stats during preprocessor fitting and data transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 col_id: str,\n",
    "                 cols_event_time: str,\n",
    "                 cols_category: List[str],\n",
    "                 cols_log_norm: List[str],\n",
    "                 time_transformation: str = 'default',\n",
    "                 print_dataset_info: bool = False):\n",
    "\n",
    "        super().__init__(col_id, cols_event_time, cols_category, cols_log_norm)\n",
    "        self.print_dataset_info = print_dataset_info\n",
    "        self.time_transformation = time_transformation\n",
    "\n",
    "    def fit(self, dt, **params):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dt : pandas.DataFrame with flat data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted preprocessor.\n",
    "        \"\"\"\n",
    "        # Reset internal state before fitting\n",
    "        self._reset()\n",
    "\n",
    "        for col in self.cols_category:\n",
    "            pd_col = dt[col].astype(str)\n",
    "            mapping = {k: i + 1 for i, k in enumerate(pd_col.value_counts().index)}\n",
    "            self.cols_category_mapping[col] = mapping\n",
    "\n",
    "            if self.print_dataset_info:\n",
    "                logger.info(f'Encoder stat for \"{col}\":\\ncodes | trx_count\\n{pd_hist(dt[col], col)}')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, copy=True):\n",
    "        \"\"\"Perform preprocessing.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame with flat data\n",
    "        copy : bool, default=None\n",
    "            Copy the input X or not.\n",
    "        Returns\n",
    "        -------\n",
    "        features : List of dicts grouped by col_id.\n",
    "        \"\"\"\n",
    "        self.check_is_fitted()\n",
    "        df_data = df.copy() if copy else df\n",
    "\n",
    "        if self.print_dataset_info:\n",
    "            logger.info(f'Found {df_data[self.col_id].nunique()} unique ids')\n",
    "\n",
    "        # event_time mapping\n",
    "        if self.time_transformation == 'none':\n",
    "            pass\n",
    "        elif self.time_transformation == 'default':\n",
    "            df_data = self._td_default(df_data, self.cols_event_time)\n",
    "        elif self.time_transformation == 'float':\n",
    "            df_data = self._td_float(df_data, self.cols_event_time)\n",
    "        elif self.time_transformation == 'gender':\n",
    "            df_data = self._td_gender(df_data, self.cols_event_time)\n",
    "        else:\n",
    "            raise NotImplementedError(f'Unknown type of data transformation: \"{self.time_transformation}\"')\n",
    "\n",
    "        for col in self.cols_category:\n",
    "            if col not in self.cols_category_mapping:\n",
    "                raise KeyError(f\"column {col} isn't in fitted category columns\")\n",
    "            pd_col = df_data[col].astype(str)\n",
    "            df_data[col] = pd_col.map(self.cols_category_mapping[col]) \\\n",
    "                .fillna(max(self.cols_category_mapping[col].values()))\n",
    "            if self.print_dataset_info:\n",
    "                logger.info(f'Encoder stat for \"{col}\":\\ncodes | trx_count\\n{pd_hist(df_data[col], col)}')\n",
    "\n",
    "        for col in self.cols_log_norm:\n",
    "            df_data[col] = np.log1p(abs(df_data[col])) * np.sign(df_data[col])\n",
    "            df_data[col] /= abs(df_data[col]).max()\n",
    "            if self.print_dataset_info:\n",
    "                logger.info(f'Encoder stat for \"{col}\":\\ncodes | trx_count\\n{pd_hist(df_data[col], col)}')\n",
    "\n",
    "        if self.print_dataset_info:\n",
    "            df = df_data.groupby(self.col_id)['event_time'].count()\n",
    "            logger.info(f'Trx count per clients:\\nlen(trx_list) | client_count\\n{pd_hist(df, \"trx_count\")}')\n",
    "\n",
    "        # column filter\n",
    "        used_columns = [col for col in df_data.columns\n",
    "                        if col in self.cols_category + self.cols_log_norm + ['event_time', self.col_id]]\n",
    "\n",
    "        logger.info('Feature collection in progress ...')\n",
    "        features = df_data[used_columns] \\\n",
    "            .assign(et_index=lambda x: x['event_time']) \\\n",
    "            .set_index([self.col_id, 'et_index']).sort_index() \\\n",
    "            .groupby(self.col_id).apply(lambda x: {k: np.array(v) for k, v in x.to_dict(orient='list').items()}) \\\n",
    "            .rename('feature_arrays').reset_index().to_dict(orient='records')\n",
    "\n",
    "        def squeeze(rec):\n",
    "            return {self.col_id: rec[self.col_id], **rec['feature_arrays']}\n",
    "        features = [squeeze(r) for r in features]\n",
    "\n",
    "        if self.print_dataset_info:\n",
    "            feature_names = list(features[0].keys())\n",
    "            logger.info(f'Feature names: {feature_names}')\n",
    "\n",
    "        logger.info(f'Prepared features for {len(features)} clients')\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def _td_default(df, cols_event_time):\n",
    "        df_event_time = df[cols_event_time].drop_duplicates()\n",
    "        df_event_time = df_event_time.sort_values(cols_event_time)\n",
    "        df_event_time['event_time'] = np.arange(len(df_event_time))\n",
    "        df = pd.merge(df, df_event_time, on=cols_event_time)\n",
    "        logger.info('Default time transformation')\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _td_float(df, col_event_time):\n",
    "        df['event_time'] = df[col_event_time].astype(float)\n",
    "        logger.info('To-float time transformation')\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _td_gender(df, col_event_time):\n",
    "        \"\"\"Gender-dataset-like transformation\n",
    "\n",
    "        'd hh:mm:ss' -> float where integer part is day number and fractional part is seconds from day begin\n",
    "        '1 00:00:00' -> 1.0\n",
    "        '1 12:00:00' -> 1.5\n",
    "        '1 01:00:00' -> 1 + 1 / 24\n",
    "        '2 23:59:59' -> 1.99\n",
    "        '432 12:00:00' -> 432.5\n",
    "\n",
    "        :param df:\n",
    "        :param col_event_time:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        padded_time = df[col_event_time].str.pad(15, 'left', '0')\n",
    "        day_part = padded_time.str[:6].astype(float)\n",
    "        time_part = pd.to_datetime(padded_time.str[7:], format='%H:%M:%S').values.astype(int) // 1e9\n",
    "        time_part = time_part % (24 * 60 * 60) / (24 * 60 * 60)\n",
    "        df['event_time'] = day_part + time_part\n",
    "        logger.info('Gender-dataset-like time transformation')\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "together-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_trx = PandasDataPreprocessor(\n",
    "    col_id='user_id',\n",
    "    cols_event_time='event_time',\n",
    "    time_transformation='none',\n",
    "    cols_category=[\"mcc_code\", \"currency_rk\"],\n",
    "    cols_log_norm=[\"transaction_amt\"],\n",
    "    print_dataset_info=False,\n",
    ")\n",
    "\n",
    "preprocessor_click = PandasDataPreprocessor(\n",
    "    col_id='user_id',\n",
    "    cols_event_time='event_time',\n",
    "    time_transformation='none',\n",
    "    cols_category=['cat_id', 'level_0', 'level_1', 'level_2'],\n",
    "    cols_log_norm=[],\n",
    "    print_dataset_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-campaign",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "monthly-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.data_load.iterable_processing.category_size_clip import CategorySizeClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "oriented-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_max_size_trx = {\n",
    "    'mcc_code': 350,\n",
    "    'currency_rk': 5,\n",
    "}\n",
    "category_max_size_click = {\n",
    "    'cat_id': 400,\n",
    "    'level_0': 400,\n",
    "    'level_1': 400,\n",
    "    'level_2': 400,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "affiliated-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trx_to_torch(seq):\n",
    "    seq = CategorySizeClip(category_max_size_trx)(seq)\n",
    "    for x in seq:\n",
    "        yield x['user_id'], {\n",
    "            'event_time': torch.from_numpy(x['event_time']).float(),\n",
    "            'mcc_code': torch.from_numpy(x['mcc_code']).int(),\n",
    "            'currency_rk': torch.from_numpy(x['currency_rk']).int(),\n",
    "            'transaction_amt': torch.from_numpy(x['transaction_amt']).float(),\n",
    "        }\n",
    "\n",
    "def click_to_torch(seq):\n",
    "    seq = CategorySizeClip(category_max_size_click)(seq)\n",
    "    for x in seq:\n",
    "        yield x['user_id'], {\n",
    "            'event_time': torch.from_numpy(x['event_time']).float(),\n",
    "            'cat_id': torch.from_numpy(x['cat_id']).int(),\n",
    "            'level_0': torch.from_numpy(x['level_0']).int(),\n",
    "            'level_1': torch.from_numpy(x['level_1']).int(),\n",
    "            'level_2': torch.from_numpy(x['level_2']).int(),\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "upset-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trx_train = dict(trx_to_torch(preprocessor_trx.fit_transform(df_trx_train)))\n",
    "features_trx_valid = dict(trx_to_torch(preprocessor_trx.transform(df_trx_valid)))\n",
    "features_trx_test = dict(trx_to_torch(preprocessor_trx.transform(df_trx_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "horizontal-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_click_train = dict(click_to_torch(preprocessor_click.fit_transform(df_click_train)))\n",
    "features_click_valid = dict(click_to_torch(preprocessor_click.transform(df_click_valid)))\n",
    "features_click_test = dict(click_to_torch(preprocessor_click.transform(df_click_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "joined-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "congressional-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessor_trx.p', 'wb') as f:\n",
    "    pickle.dump(preprocessor_trx, f)\n",
    "with open('preprocessor_click.p', 'wb') as f:\n",
    "    pickle.dump(preprocessor_click, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "latter-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtb_code.data import PairedDataset, paired_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "digital-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.data_load import augmentation_chain\n",
    "from dltranz.data_load.augmentations.seq_len_limit import SeqLenLimit\n",
    "from dltranz.data_load.augmentations.random_slice import RandomSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "equivalent-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomSample:\n",
    "    def __init__(self, min_len, max_len, rate_for_min=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.min_len = min_len\n",
    "        self.max_len = max_len\n",
    "        self.rate_for_min = rate_for_min\n",
    "\n",
    "    def __call__(self, x):\n",
    "        seq_len = len(next(iter(x.values())))\n",
    "\n",
    "        idx = self.get_idx(seq_len)\n",
    "        new_x = {k: v[idx] for k, v in x.items()}\n",
    "        return new_x\n",
    "\n",
    "    def get_idx(self, seq_len):\n",
    "        new_idx = np.arange(seq_len)\n",
    "\n",
    "        min_len, max_len = self.get_min_max(seq_len)\n",
    "        if max_len < min_len:\n",
    "            return new_idx\n",
    "        new_len = random.randint(min_len, max_len)\n",
    "\n",
    "        return np.sort(np.random.choice(new_idx, size=new_len, replace=False))\n",
    "\n",
    "    def get_min_max(self, seq_len):\n",
    "        max_len = int(min(self.max_len, seq_len))\n",
    "        min_len = int(min(self.min_len, seq_len * self.rate_for_min))\n",
    "        if min_len < 1:\n",
    "            min_len = 1\n",
    "        return min_len, max_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "reflected-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDuplicate:\n",
    "    def __init__(self, col_check, col_new_cnt=None, keep='first'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.col_check = col_check\n",
    "        self.col_new_cnt = col_new_cnt\n",
    "        if keep != 'first':\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        idx, new_cnt = self.get_idx(x[self.col_check])\n",
    "        new_x = {k: v[idx] for k, v in x.items()}\n",
    "        if self.col_new_cnt is not None:\n",
    "            new_x[self.col_new_cnt] = new_cnt\n",
    "        return new_x\n",
    "\n",
    "    def get_idx(self, x):\n",
    "        diff = np.diff(x, prepend=x[0] - 1)\n",
    "        new_ix = np.where(diff != 0)[0]\n",
    "        new_cnt = np.diff(new_ix, append=len(x))\n",
    "        return new_ix, new_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-korea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "crude-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.seq_encoder import create_encoder\n",
    "from dltranz.metric_learn.sampling_strategies import get_sampling_strategy\n",
    "from dltranz.metric_learn.losses import get_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "productive-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtb_code.metrics import PrecisionK, MeanReciprocalRankK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-defeat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lesbian-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedModule(pl.LightningModule):\n",
    "    def __init__(self, params, neg_count, k,\n",
    "                 lr, weight_decay,\n",
    "                 step_size, gamma,\n",
    "                 base_lr, max_lr, step_size_up, step_size_down,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['params', 'loss_fn', 'loss_w'])\n",
    "        \n",
    "        self.seq_encoder_trx = torch.nn.Sequential(\n",
    "            create_encoder(params['trx_seq'], is_reduce_sequence=True),\n",
    "#             torch.nn.Linear(params['trx_seq.rnn.hidden_size'], params['head_size']),\n",
    "        )\n",
    "        self.seq_encoder_click = torch.nn.Sequential(\n",
    "            create_encoder(params['click_seq'], is_reduce_sequence=True),\n",
    "#             torch.nn.Linear(params['click_seq.rnn.hidden_size'], params['head_size']),\n",
    "        )\n",
    "                \n",
    "        self.train_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.train_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        self.valid_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.valid_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        if self.hparams.step_size is not None:\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optim, step_size=self.hparams.step_size, gamma=self.hparams.gamma)\n",
    "        else:\n",
    "            sheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "                optim,\n",
    "                base_lr=self.hparams.base_lr, max_lr=self.hparams.max_lr,\n",
    "                step_size_up=self.hparams.step_size_up,\n",
    "                step_size_down=self.hparams.step_size_down,\n",
    "                cycle_momentum=False,\n",
    "            )\n",
    "            scheduler = {'scheduler': sheduler, 'interval': 'step'}\n",
    "        return [optim], [scheduler]\n",
    "    \n",
    "#     def forward(self, batch):\n",
    "#         x_trx, x_click = batch\n",
    "#         z_trx = self.seq_encoder_trx(x_trx)  # B, H\n",
    "#         z_click = self.seq_encoder_click(x_click)  # B, H\n",
    "        \n",
    "#         B, H = z_trx.size()\n",
    "#         logits = (z_trx * z_click).sum(dim=1)  # B(trx),\n",
    "#         return logits\n",
    "    \n",
    "    def pos_pairs(self, a, b):\n",
    "        l2 = torch.nn.functional.pairwise_distance(a, b)  # B(trx),\n",
    "        return l2\n",
    "    \n",
    "    def neg_pairs(self, a, b):\n",
    "        l2 = torch.nn.functional.pairwise_distance(a.unsqueeze(1), b.unsqueeze(0))  # B(trx) * B(click)\n",
    "        B, _ = l2.size()\n",
    "        device = l2.device\n",
    "        neg_mask = torch.eye(B, device=device) == 1\n",
    "        l2 = l2.masked_fill(neg_mask, 10)\n",
    "        k = min(self.hparams.neg_count, B - 1)\n",
    "        neg_pairs = torch.topk(l2, k=k, dim=1, largest=False).values\n",
    "        return neg_pairs\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_trx, x_click = batch\n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # B, H\n",
    "\n",
    "        z_trx = torch.nn.functional.normalize(z_trx, dim=1)\n",
    "        z_click = torch.nn.functional.normalize(z_click, dim=1)\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            l2 = torch.nn.functional.pairwise_distance(z_trx.unsqueeze(1), z_click.unsqueeze(0))\n",
    "            # B(trx) * B(click)\n",
    "            self.train_precision(-l2)\n",
    "            self.train_mrr(-l2)\n",
    "        \n",
    "        B, H = z_trx.size()\n",
    "        loss_sum, cnt = 0.0, 0\n",
    "        res = self.pos_pairs(z_trx, z_click)\n",
    "        self.log('logits_metrics/l2_pos_trx_click', res.mean())\n",
    "        loss_sum += res.pow(2).sum()\n",
    "        cnt += res.size(0)\n",
    "        \n",
    "        res = self.neg_pairs(z_trx, z_trx)\n",
    "        self.log('logits_metrics/l2_neg_trx_trx', res.mean())\n",
    "        loss_sum += torch.relu(0.5 - res).pow(2).sum()\n",
    "        cnt += res.size(0) * res.size(1)\n",
    "\n",
    "        res = self.neg_pairs(z_trx, z_click)\n",
    "        self.log('logits_metrics/l2_neg_trx_click', res.mean())\n",
    "        loss_sum += torch.relu(0.5 - res).pow(2).sum()\n",
    "        cnt += res.size(0) * res.size(1)\n",
    "\n",
    "        res = self.neg_pairs(z_click, z_click)\n",
    "        self.log('logits_metrics/l2_neg_click_click', res.mean())\n",
    "        loss_sum += torch.relu(0.5 - res).pow(2).sum()\n",
    "        cnt += res.size(0) * res.size(1)\n",
    "\n",
    "        loss = loss_sum / cnt\n",
    "        self.log('loss/l2', res.mean())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_trx, x_click = batch\n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # B, H\n",
    "\n",
    "        z_trx = torch.nn.functional.normalize(z_trx, dim=1)\n",
    "        z_click = torch.nn.functional.normalize(z_click, dim=1)\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            l2 = torch.nn.functional.pairwise_distance(z_trx.unsqueeze(1), z_click.unsqueeze(0))\n",
    "            # B(trx) * B(click)\n",
    "            self.valid_precision(-l2)\n",
    "            self.valid_mrr(-l2)\n",
    "\n",
    "    def training_epoch_end(self, _):\n",
    "        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n",
    "        self.log('train_metrics/mrr', self.train_mrr, prog_bar=True)\n",
    "\n",
    "    def validation_epoch_end(self, _):\n",
    "        self.log('valid_metrics/precision', self.valid_precision, prog_bar=True)\n",
    "        self.log('valid_metrics/mrr', self.valid_mrr, prog_bar=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "black-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_model = PairedModule(\n",
    "    ConfigFactory.parse_string('''\n",
    "    trx_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            mcc_code: {in: 350, out: 64},\n",
    "            currency_rk: {in: 10, out: 4}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            transaction_amt: identity\n",
    "          }\n",
    "        },\n",
    "        encoder_type: rnn,\n",
    "        rnn: {\n",
    "          type: gru,\n",
    "          hidden_size: 64,\n",
    "          bidir: false,\n",
    "          trainable_starter: static\n",
    "        }\n",
    "    }\n",
    "    click_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            cat_id: {in: 400, out: 64},\n",
    "            level_0: {in: 400, out: 16}\n",
    "            level_1: {in: 400, out: 8}\n",
    "            level_2: {in: 400, out: 4}\n",
    "          },\n",
    "          numeric_values: {\n",
    "          }\n",
    "        },\n",
    "        encoder_type: rnn,\n",
    "        rnn: {\n",
    "          type: gru,\n",
    "          hidden_size: 64,\n",
    "          bidir: false,\n",
    "          trainable_starter: static\n",
    "        }    \n",
    "    }\n",
    "'''),                     \n",
    "    neg_count=8, k=17,\n",
    "    lr=0.004, weight_decay=0,\n",
    "    step_size=500, gamma=0.3,\n",
    "    base_lr=0.0005, max_lr=0.004, step_size_up=300, step_size_down=900,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "endless-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = PairedDataset(\n",
    "    np.concatenate([\n",
    "        df_matching_train[lambda x: x['rtk'].ne('0')].values,\n",
    "    ], axis=1), \n",
    "    data=[\n",
    "        features_trx_train,\n",
    "        features_click_train,\n",
    "    ],\n",
    "    augmentations=[\n",
    "        augmentation_chain(RandomSlice(256, 512)),  # 2000\n",
    "        augmentation_chain(DropDuplicate('cat_id'), RandomSlice(256, 512)),  # 5000\n",
    "    ],\n",
    ")\n",
    "\n",
    "dataset_valid = PairedDataset(\n",
    "    np.concatenate([\n",
    "        df_matching_valid[lambda x: x['rtk'].ne('0')].values,\n",
    "    ], axis=1), \n",
    "    data=[\n",
    "        features_trx_valid,\n",
    "        features_click_valid,\n",
    "    ],\n",
    "    augmentations=[\n",
    "        augmentation_chain(RandomSlice(256, 512)),  # 2000\n",
    "        augmentation_chain(DropDuplicate('cat_id'), RandomSlice(256, 512)),  # 5000\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "middle-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    batch_size=512,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=512,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "twenty-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[3],\n",
    "    max_steps=30000,\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            every_n_train_steps=1000, save_top_k=-1,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-testimony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | seq_encoder_trx   | Sequential          | 48.4 K\n",
      "1 | seq_encoder_click | Sequential          | 67.2 K\n",
      "2 | train_precision   | PrecisionK          | 0     \n",
      "3 | train_mrr         | MeanReciprocalRankK | 0     \n",
      "4 | valid_precision   | PrecisionK          | 0     \n",
      "5 | valid_mrr         | MeanReciprocalRankK | 0     \n",
      "----------------------------------------------------------\n",
      "115 K     Trainable params\n",
      "0         Non-trainable params\n",
      "115 K     Total params\n",
      "0.463     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1bb70841c8422786c5512f9e488082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0><function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "\n",
      "AssertionError  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      ":     can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "      File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0><function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>self._shutdown_workers()\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        if w.is_alive():    self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():AssertionError\n",
      ":   File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process      File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    AssertionErrorif w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError: \n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "Exception ignored in:   File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>Exception ignored in: \n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>Traceback (most recent call last):\n",
      "if w.is_alive():\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "AssertionError      File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      ": if w.is_alive():can only test a child process    \n",
      "\n",
      "if w.is_alive():  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "Exception ignored in:   File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>    \n",
      "if w.is_alive():Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "          File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "    AssertionError  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "self._shutdown_workers(): \n",
      "    can only test a child process  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "\n",
      "      File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Exception ignored in:     Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>self._shutdown_workers()  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "\n",
      "      File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()    \n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "if w.is_alive():  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
      "\n",
      "\n",
      "AssertionErrorAssertionError  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      ": : can only test a child process    can only test a child process\n",
      "if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1db74f0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/mnt2/kireev/pipenv_envs/vtb-6O4wd6SN/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(sup_model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-airfare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-filter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtb",
   "language": "python",
   "name": "vtb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
