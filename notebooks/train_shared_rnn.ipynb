{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "simplified-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/kireev/pycharm-deploy/vtb\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "subtle-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriented-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "labeled-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhocon import ConfigFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outer-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monthly-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.data_load.iterable_processing.category_size_clip import CategorySizeClip\n",
    "from dltranz.data_load import augmentation_chain\n",
    "from dltranz.data_load.augmentations.seq_len_limit import SeqLenLimit\n",
    "from dltranz.data_load.augmentations.random_slice import RandomSlice\n",
    "\n",
    "from dltranz.seq_encoder import create_encoder\n",
    "\n",
    "from dltranz.metric_learn.sampling_strategies import get_sampling_strategy\n",
    "from dltranz.metric_learn.losses import get_loss\n",
    "\n",
    "from dltranz.tb_interface import get_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latter-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtb_code.data import PairedDataset, paired_collate_fn, PairedZeroDataset, DropDuplicate\n",
    "from vtb_code.metrics import PrecisionK, MeanReciprocalRankK, ValidationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-ready",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepted-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_ID = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "under-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_id_test = FOLD_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifty-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_count = len(glob('data/train_matching_*.csv'))\n",
    "folds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suburban-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold_id_valid = np.random.choice([i for i in range(folds_count) if i != fold_id_test], size=1)[0]\n",
    "fold_id_valid = (fold_id_test + 1) % folds_count\n",
    "fold_id_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confidential-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_train = pd.concat([pd.read_csv(f'data/train_matching_{i}.csv')\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_matching_valid = pd.read_csv(f'data/train_matching_{fold_id_valid}.csv')\n",
    "df_matching_test = pd.read_csv(f'data/train_matching_{fold_id_test}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smooth-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11721, 2930, 2930]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(df) for df in [df_matching_train, df_matching_valid, df_matching_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "toxic-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 4.37 s, total: 16.5 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(f'data/features_f{FOLD_ID}.pickle', 'rb') as f:\n",
    "    (\n",
    "        features_trx_train,\n",
    "        features_trx_valid,\n",
    "        features_trx_test,\n",
    "        features_trx_puzzle,\n",
    "        features_click_train,\n",
    "        features_click_valid,\n",
    "        features_click_test,\n",
    "        features_click_puzzle,\n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-hartford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pursuant-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.seq_encoder.utils import NormEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crude-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Scorer(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        B, H = x.size()\n",
    "        a, b =x[:, :H // 2], x[:, H // 2:]\n",
    "        return -(a - b).pow(2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mechanical-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrxTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "#         x.payload['mcc_code'] = torch.clamp(x.payload['mcc_code'], 0, 300)\n",
    "#         x.payload['c_cnt_clamp'] = torch.clamp(x.payload['c_cnt'], 0, 20).int()\n",
    "        return x\n",
    "    \n",
    "class CustomClickTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "#         x.payload['cat_id'] = torch.clamp(x.payload['cat_id'], 0, 300)\n",
    "#         x.payload['level_0'] = torch.clamp(x.payload['level_0'], 0, 200)\n",
    "#         x.payload['level_1'] = torch.clamp(x.payload['level_1'], 0, 200)\n",
    "#         x.payload['level_2'] = torch.clamp(x.payload['level_2'], 0, 200)\n",
    "#         x.payload['c_cnt_clamp'] = torch.clamp(x.payload['c_cnt'], 0, 20).int()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbc086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "395037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeaturesTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        et = x.payload['event_time'].int()\n",
    "        et_day = et.div(24 * 60 * 60, rounding_mode='floor').int()\n",
    "        x.payload['hour'] = et.div(60 * 60, rounding_mode='floor') % 24 + 1\n",
    "#         x.payload['weekday'] = et.div(60 * 60 * 24, rounding_mode='floor') % 7 + 1\n",
    "#         x.payload['hour_s'] = torch.sin(2 * np.pi * (et % (60 * 60 * 24)) / (60 * 60 * 24))\n",
    "#         x.payload['hour_c'] = torch.cos(2 * np.pi * (et % (60 * 60 * 24)) / (60 * 60 * 24))\n",
    "#         x.payload['day_diff'] = torch.clamp(torch.diff(et_day, prepend=et_day[:, :1], dim=1), 0, 14)\n",
    "#         x.payload['day_diff_c'] = torch.clamp(torch.diff(et, prepend=et[:, :1], dim=1) / (60 * 60 * 24), 0, 14)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b57fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c992ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.trx_encoder import TrxEncoder, PaddedBatch\n",
    "from dltranz.seq_encoder.rnn_encoder import RnnEncoder\n",
    "from dltranz.seq_encoder.utils import LastStepEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92667f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca25b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBLinear(torch.nn.Linear):\n",
    "    def forward(self, x: PaddedBatch):\n",
    "        return PaddedBatch(super().forward(x.payload), x.seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lesbian-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedModule(pl.LightningModule):\n",
    "    def __init__(self, params, sampling_strategy_params, loss_params, k,\n",
    "                 lr, weight_decay,\n",
    "                 step_size, gamma,\n",
    "                 base_lr, max_lr, step_size_up, step_size_down,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        t = TrxEncoder(params['trx_seq.trx_encoder'])\n",
    "        print(t.output_size)\n",
    "        self.rnn_enc =  torch.nn.Sequential(\n",
    "            RnnEncoder(params['common_trx_size'], params['rnn']), \n",
    "            LastStepEncoder(),\n",
    "            NormEncoder(),\n",
    "        )\n",
    "        self.seq_encoder_trx_size = params['rnn.hidden_size']\n",
    "        self._seq_encoder_trx = torch.nn.Sequential(\n",
    "            CustomTrxTransform(),\n",
    "            DateFeaturesTransform(),\n",
    "            t, PBLinear(t.output_size, params['common_trx_size']),\n",
    "        )\n",
    "        t = TrxEncoder(params['click_seq.trx_encoder'])\n",
    "        print(t.output_size)\n",
    "        self._seq_encoder_click = torch.nn.Sequential(\n",
    "            CustomClickTransform(),\n",
    "            DateFeaturesTransform(),\n",
    "            t, PBLinear(t.output_size, params['common_trx_size']),\n",
    "        )\n",
    "        \n",
    "        self.cls = torch.nn.Sequential(\n",
    "            L2Scorer(),\n",
    "        )\n",
    "\n",
    "        sampling_strategy = get_sampling_strategy(sampling_strategy_params)\n",
    "        self.loss_fn = get_loss(loss_params, sampling_strategy)\n",
    "        \n",
    "        self.train_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.train_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        self.valid_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.valid_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        \n",
    "    def seq_encoder_trx(self, x):\n",
    "        x = self._seq_encoder_trx(x)\n",
    "        return self.rnn_enc(x)\n",
    "    \n",
    "    def seq_encoder_click(self, x):\n",
    "        x = self._seq_encoder_click(x)\n",
    "        return self.rnn_enc(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        if self.hparams.step_size is not None:\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optim, step_size=self.hparams.step_size, gamma=self.hparams.gamma)\n",
    "        else:\n",
    "            sheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "                optim,\n",
    "                base_lr=self.hparams.base_lr, max_lr=self.hparams.max_lr,\n",
    "                step_size_up=self.hparams.step_size_up,\n",
    "                step_size_down=self.hparams.step_size_down,\n",
    "                cycle_momentum=False,\n",
    "            )\n",
    "            scheduler = {'scheduler': sheduler, 'interval': 'step'}\n",
    "        return [optim], [scheduler]\n",
    "    \n",
    "#     def forward(self, batch):\n",
    "#         return logits\n",
    "            \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_trx, l_trx, m_trx, x_click, l_click, m_click = batch\n",
    "        \n",
    "        self.log('seq_le/trx_mean', x_trx.seq_lens.float().mean())\n",
    "        self.log('seq_len/click_mean', x_click.seq_lens.float().mean())\n",
    "        \n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # B, H\n",
    "        \n",
    "        B = z_trx.size(0)\n",
    "        device = z_trx.device\n",
    "        \n",
    "        loss = self.loss_fn(\n",
    "            torch.cat([z_trx, z_click], dim=0),\n",
    "            torch.cat([l_trx, l_click], dim=0),\n",
    "        )\n",
    "        self.log('loss/loss_ml', loss, prog_bar=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = -(z_trx.unsqueeze(1) - z_click.unsqueeze(0)).pow(2).sum(dim=2)\n",
    "            out = out[m_trx == 0][:, m_click == 0]\n",
    "            T, C = out.size()\n",
    "            assert T == C\n",
    "            n_samples = z_trx.size(0) // (l_trx.max().item() + 1)\n",
    "            for i in range(n_samples):\n",
    "                l2 = out[i::n_samples, i::n_samples]\n",
    "                self.train_precision(l2)\n",
    "                self.train_mrr(l2)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, _):\n",
    "        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n",
    "        self.log('train_metrics/mrr', self.train_mrr, prog_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-conference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "equivalent-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confused-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    PairedZeroDataset(\n",
    "        pd.concat([df_matching_train, df_matching_test], axis=0)[lambda x: x['rtk'].ne('0')].values,\n",
    "        data=[\n",
    "            dict(chain(features_trx_train.items(), features_trx_test.items())),\n",
    "            dict(chain(features_click_train.items(), features_click_test.items())),\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 2000\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 5000\n",
    "        ],\n",
    "        n_sample=2,\n",
    "    ),\n",
    "    collate_fn=PairedZeroDataset.collate_fn,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    batch_size=batch_size,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01f53707",
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = []\n",
    "v1 = []\n",
    "for batch in train_dl:\n",
    "    et, mask = batch[0].payload['event_time'].int(), batch[0].seq_len_mask.bool()\n",
    "    et_day = et.div(24 * 60 * 60, rounding_mode='floor').int()\n",
    "    hour = et.div(60 * 60, rounding_mode='floor') % 24 + 1\n",
    "    day_diff = torch.clamp(torch.diff(et_day, prepend=et_day[:, :1], dim=1), 0, 14)\n",
    "    v0.append(day_diff[mask])\n",
    "\n",
    "    et, mask = batch[3].payload['event_time'].int(), batch[3].seq_len_mask.bool()\n",
    "    et_day = et.div(24 * 60 * 60, rounding_mode='floor').int()\n",
    "    hour = et.div(60 * 60, rounding_mode='floor') % 24 + 1\n",
    "    day_diff = torch.clamp(torch.diff(et_day, prepend=et_day[:, :1], dim=1), 0, 14)\n",
    "    v1.append(day_diff[mask])\n",
    "    \n",
    "v0, v1 = [torch.cat(t) for t in [v0, v1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "206895d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "axs[0].bar(*[t.numpy() for t in torch.unique(v0, return_counts=True)])\n",
    "axs[1].bar(*[t.numpy() for t in torch.unique(v1, return_counts=True)])\n",
    "axs[0].set_yscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544518b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5aff1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    PairedZeroDataset(\n",
    "        pd.concat([df_matching_train, df_matching_test], axis=0)[lambda x: x['rtk'].ne('0')].values,\n",
    "        data=[\n",
    "            dict(chain(features_trx_train.items(), features_trx_test.items())),\n",
    "            dict(chain(features_click_train.items(), features_click_test.items())),\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n",
    "        ],\n",
    "        n_sample=2,\n",
    "    ),\n",
    "    collate_fn=PairedZeroDataset.collate_fn,\n",
    "    shuffle=True,\n",
    "    num_workers=24,\n",
    "    batch_size=batch_size,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valid_dl_trx = torch.utils.data.DataLoader(\n",
    "    PairedDataset(\n",
    "        np.sort(df_matching_valid['bank'].unique()).reshape(-1, 1), \n",
    "        data=[\n",
    "            features_trx_valid,\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), SeqLenLimit(2000)),  # 2000\n",
    "        ],\n",
    "        n_sample=1,\n",
    "    ),\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=512,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valid_dl_click = torch.utils.data.DataLoader(\n",
    "    PairedDataset(\n",
    "        np.sort(df_matching_valid[lambda x: x['rtk'].ne('0')]['rtk'].unique()).reshape(-1, 1),\n",
    "        data=[\n",
    "            features_click_valid,\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), SeqLenLimit(5000)),  # 5000\n",
    "        ],\n",
    "        n_sample=1,\n",
    "    ),\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=512,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "black-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "sup_model = PairedModule(\n",
    "    ConfigFactory.parse_string('''\n",
    "    common_trx_size: 256\n",
    "    rnn: {\n",
    "      type: gru,\n",
    "      hidden_size: 256,\n",
    "      bidir: false,\n",
    "      trainable_starter: static\n",
    "    }\n",
    "    trx_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            mcc_code: {in: 350, out: 64},\n",
    "            currency_rk: {in: 10, out: 4}\n",
    "            hour: {in: 30, out: 16}\n",
    "            # day_diff: {in: 15, out: 8}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            transaction_amt: identity\n",
    "            c_cnt: log\n",
    "          }\n",
    "          was_logified: false\n",
    "          log_scale_factor: 1.0\n",
    "        },\n",
    "    }\n",
    "    click_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            cat_id: {in: 400, out: 64},\n",
    "            level_0: {in: 400, out: 16}\n",
    "            level_1: {in: 400, out: 8}\n",
    "            level_2: {in: 400, out: 4}\n",
    "            hour: {in: 30, out: 16}\n",
    "            # day_diff: {in: 15, out: 8}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            c_cnt: log\n",
    "          }\n",
    "          was_logified: false\n",
    "          log_scale_factor: 1.0\n",
    "        },\n",
    "    }\n",
    "'''),                     \n",
    "    sampling_strategy_params=ConfigFactory.parse_string('''\n",
    "        train.sampling_strategy: SemiHardTriplets\n",
    "        # train.balanced: true\n",
    "        # train.neg_count: 10\n",
    "    '''),\n",
    "    loss_params=ConfigFactory.parse_string('''\n",
    "        train.loss: TripletLoss\n",
    "        # train.num_steps: 50\n",
    "        train.margin: 0.5\n",
    "    '''),\n",
    "    k=100 * batch_size // 3000,\n",
    "    lr=0.005, weight_decay=0,\n",
    "    step_size=10 // 10, gamma=0.4 ** (1 / 10),\n",
    "    base_lr=0.0005, max_lr=0.004, step_size_up=300, step_size_down=900,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecological-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(pl.Callback):\n",
    "    def __init__(self, v_trx, v_click, target, device, device_main, k=100, batch_size=1024):\n",
    "        self.v_trx = v_trx\n",
    "        self.v_click = v_click\n",
    "        self.target = target\n",
    "        self.device = device\n",
    "        self.device_main = device_main\n",
    "        self.k = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        was_traning = False\n",
    "        if pl_module.training:\n",
    "            pl_module.eval()\n",
    "            was_traning = True\n",
    "\n",
    "        pl_module.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            z_trx = []\n",
    "            for ((x_trx, _),) in self.v_trx:\n",
    "                z_trx.append(pl_module.seq_encoder_trx(x_trx.to(self.device)))\n",
    "            z_trx = torch.cat(z_trx, dim=0)\n",
    "            z_click = []\n",
    "            for ((x_click, _),) in self.v_click:\n",
    "                z_click.append(pl_module.seq_encoder_click(x_click.to(self.device)))\n",
    "            z_click = torch.cat(z_click, dim=0)\n",
    "\n",
    "            T = z_trx.size(0)\n",
    "            C = z_click.size(0)\n",
    "            device = z_trx.device\n",
    "            ix_t = torch.arange(T, device=device).view(-1, 1).expand(T, C).flatten()\n",
    "            ix_c = torch.arange(C, device=device).view(1, -1).expand(T, C).flatten()\n",
    "\n",
    "            z_out = []\n",
    "            for i in range(0, len(ix_t), self.batch_size):\n",
    "                z_pairs = torch.cat([\n",
    "                    z_trx[ix_t[i:i + self.batch_size]],\n",
    "                    z_click[ix_c[i:i + self.batch_size]],\n",
    "                ], dim=1)\n",
    "                z_out.append(pl_module.cls(z_pairs).unsqueeze(1))\n",
    "            z_out = torch.cat(z_out, dim=0).view(T, C)\n",
    "\n",
    "            precision, mrr, r1 = self.logits_to_metrics(z_out)\n",
    "\n",
    "            pl_module.log('valid_full_metrics/precision', precision, prog_bar=True)\n",
    "            pl_module.log('valid_full_metrics/mrr', mrr, prog_bar=False)\n",
    "            pl_module.log('valid_full_metrics/r1', r1, prog_bar=False)\n",
    "\n",
    "        pl_module.to(self.device_main)\n",
    "        if was_traning:\n",
    "            pl_module.train()\n",
    "\n",
    "    def logits_to_metrics(self, z_out):\n",
    "        T, C = z_out.size()\n",
    "        z_ranks = torch.zeros_like(z_out)\n",
    "        z_ranks[\n",
    "            torch.arange(T, device=self.device).view(-1, 1).expand(T, C),\n",
    "            torch.argsort(z_out, dim=1, descending=True),\n",
    "        ] = torch.arange(C, device=self.device).float().view(1, -1).expand(T, C) + 1\n",
    "        z_ranks = torch.cat([\n",
    "            torch.ones(T, device=self.device).float().view(-1, 1),\n",
    "            z_ranks + 1,\n",
    "        ], dim=1)\n",
    "        \n",
    "        click_uids = np.concatenate([['0'], self.v_click.dataset.pairs[:, 0]])\n",
    "        true_ranks = z_ranks[\n",
    "            np.arange(T),\n",
    "            np.searchsorted(click_uids,\n",
    "                            self.target.set_index('bank')['rtk'].loc[self.v_trx.dataset.pairs[:, 0]].values)\n",
    "        ]\n",
    "        precision = torch.where(true_ranks <= self.k,\n",
    "                                torch.ones(1, device=self.device), torch.zeros(1, device=self.device)).mean()\n",
    "        mrr = torch.where(true_ranks <= self.k, 1 / true_ranks, torch.zeros(1, device=self.device)).mean()\n",
    "        r1 = 2 * mrr * precision / (mrr + precision)\n",
    "        return precision, mrr, r1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "twenty-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[3],\n",
    "    max_steps=3000,\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            every_n_train_steps=1000, save_top_k=-1,\n",
    "        ),\n",
    "        ValidationCallback(valid_dl_trx, valid_dl_click, df_matching_valid,\n",
    "                           torch.device('cuda:2'), torch.device('cuda:3')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "brief-testimony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name               | Type                | Params\n",
      "-----------------------------------------------------------\n",
      "0 | rnn_enc            | Sequential          | 395 K \n",
      "1 | _seq_encoder_trx   | Sequential          | 45.2 K\n",
      "2 | _seq_encoder_click | Sequential          | 65.4 K\n",
      "3 | cls                | Sequential          | 0     \n",
      "4 | train_precision    | PrecisionK          | 0     \n",
      "5 | train_mrr          | MeanReciprocalRankK | 0     \n",
      "6 | valid_precision    | PrecisionK          | 0     \n",
      "7 | valid_mrr          | MeanReciprocalRankK | 0     \n",
      "-----------------------------------------------------------\n",
      "505 K     Trainable params\n",
      "0         Non-trainable params\n",
      "505 K     Total params\n",
      "2.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31572c83fb043c885e89af055c91b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(sup_model, train_dl)  # valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2663d886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0: v1\\n1: v2\\n2: v3\\n3: v4\\n4: v\\n5: v0\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "0: v1\n",
    "1: v2\n",
    "2: v3\n",
    "3: v4\n",
    "4: v5\n",
    "5: v0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-evanescence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "supreme-subsection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_m = get_scalars('lightning_logs/').set_index('version').loc[[f'version_{i}' for i in [1, 2, 3, 4, 5, 0]]]\n",
    "\n",
    "# df = df_m[lambda x: x['tag'].str.startswith('train_metrics')] \\\n",
    "# .pivot(index='step', columns='tag', values='value')\n",
    "# _, axs = plt.subplots(2, 1, figsize=(16, 15))\n",
    "# for col, ax in zip(df.columns, axs):\n",
    "#     df[col].plot(ax=ax, title=col, grid=True)\n",
    "# plt.show()\n",
    "\n",
    "# df = df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    "# .pivot(index='step', columns='tag', values='value')\n",
    "# _, axs = plt.subplots(3, 1, figsize=(16, 18))\n",
    "# for col, ax in zip(df.columns, axs):\n",
    "#     df[col].plot(ax=ax, title=col, grid=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "surgical-amateur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>version</th>\n",
       "      <th>version_0</th>\n",
       "      <th>version_1</th>\n",
       "      <th>version_2</th>\n",
       "      <th>version_3</th>\n",
       "      <th>version_4</th>\n",
       "      <th>version_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>valid_full_metrics/mrr</th>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_full_metrics/precision</th>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>0.4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_full_metrics/r1</th>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.2679</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>0.2739</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.2706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "version                       version_0  version_1  version_2  version_3  \\\n",
       "tag                                                                        \n",
       "valid_full_metrics/mrr           0.1935     0.1894     0.1928     0.1937   \n",
       "valid_full_metrics/precision     0.4647     0.4573     0.4580     0.4676   \n",
       "valid_full_metrics/r1            0.2733     0.2679     0.2714     0.2739   \n",
       "\n",
       "version                       version_4  version_5  \n",
       "tag                                                 \n",
       "valid_full_metrics/mrr           0.1908     0.1922  \n",
       "valid_full_metrics/precision     0.4635     0.4570  \n",
       "valid_full_metrics/r1            0.2703     0.2706  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    ".pivot_table(index='tag', columns='version', values='value', aggfunc=lambda x: x[-1]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b21b9bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "valid_full_metrics/mrr          0.1921\n",
       "valid_full_metrics/precision    0.4614\n",
       "valid_full_metrics/r1           0.2712\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    ".pivot_table(index='tag', columns='version', values='value', aggfunc=lambda x: x[-1]).mean(axis=1).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfee29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtb",
   "language": "python",
   "name": "vtb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
