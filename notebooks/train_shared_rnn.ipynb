{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "simplified-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/kireev/pycharm-deploy/vtb\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "subtle-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriented-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "labeled-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhocon import ConfigFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outer-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monthly-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.data_load.iterable_processing.category_size_clip import CategorySizeClip\n",
    "from dltranz.data_load import augmentation_chain\n",
    "from dltranz.data_load.augmentations.seq_len_limit import SeqLenLimit\n",
    "from dltranz.data_load.augmentations.random_slice import RandomSlice\n",
    "\n",
    "from dltranz.seq_encoder import create_encoder\n",
    "\n",
    "from dltranz.metric_learn.sampling_strategies import get_sampling_strategy\n",
    "from dltranz.metric_learn.losses import get_loss\n",
    "\n",
    "from dltranz.tb_interface import get_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latter-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtb_code.data import PairedDataset, paired_collate_fn, PairedZeroDataset, DropDuplicate\n",
    "from vtb_code.metrics import PrecisionK, MeanReciprocalRankK, ValidationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-ready",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepted-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "under-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_id_test = FOLD_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifty-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_count = len(glob('data/train_matching_*.csv'))\n",
    "folds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suburban-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fold_id_valid = np.random.choice([i for i in range(folds_count) if i != fold_id_test], size=1)[0]\n",
    "fold_id_valid = (fold_id_test + 1) % folds_count\n",
    "fold_id_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confidential-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_train = pd.concat([pd.read_csv(f'data/train_matching_{i}.csv')\n",
    "                              for i in range(folds_count) \n",
    "                              if i not in (fold_id_test, fold_id_valid)])\n",
    "df_matching_valid = pd.read_csv(f'data/train_matching_{fold_id_valid}.csv')\n",
    "df_matching_test = pd.read_csv(f'data/train_matching_{fold_id_test}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smooth-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11720, 2931, 2930]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(df) for df in [df_matching_train, df_matching_valid, df_matching_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "toxic-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 4.64 s, total: 16.7 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(f'data/features_f{FOLD_ID}.pickle', 'rb') as f:\n",
    "    (\n",
    "        features_trx_train,\n",
    "        features_trx_valid,\n",
    "        features_trx_test,\n",
    "        features_trx_puzzle,\n",
    "        features_click_train,\n",
    "        features_click_valid,\n",
    "        features_click_test,\n",
    "        features_click_puzzle,\n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-hartford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pursuant-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.seq_encoder.utils import NormEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crude-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Scorer(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        B, H = x.size()\n",
    "        a, b =x[:, :H // 2], x[:, H // 2:]\n",
    "        return -(a - b).pow(2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mechanical-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrxTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "#         x.payload['mcc_code'] = torch.clamp(x.payload['mcc_code'], 0, 300)\n",
    "#         x.payload['c_cnt_clamp'] = torch.clamp(x.payload['c_cnt'], 0, 20).int()\n",
    "        return x\n",
    "    \n",
    "class CustomClickTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "#         x.payload['cat_id'] = torch.clamp(x.payload['cat_id'], 0, 300)\n",
    "#         x.payload['level_0'] = torch.clamp(x.payload['level_0'], 0, 200)\n",
    "#         x.payload['level_1'] = torch.clamp(x.payload['level_1'], 0, 200)\n",
    "#         x.payload['level_2'] = torch.clamp(x.payload['level_2'], 0, 200)\n",
    "#         x.payload['c_cnt_clamp'] = torch.clamp(x.payload['c_cnt'], 0, 20).int()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbc086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "395037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeaturesTransform(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        et = x.payload['event_time'].int()\n",
    "        et_day = et.div(24 * 60 * 60, rounding_mode='floor').int()\n",
    "        x.payload['hour'] = et.div(60 * 60, rounding_mode='floor') % 24 + 1\n",
    "#         x.payload['weekday'] = et.div(60 * 60 * 24, rounding_mode='floor') % 7 + 1\n",
    "#         x.payload['hour_s'] = torch.sin(2 * np.pi * (et % (60 * 60 * 24)) / (60 * 60 * 24))\n",
    "#         x.payload['hour_c'] = torch.cos(2 * np.pi * (et % (60 * 60 * 24)) / (60 * 60 * 24))\n",
    "#         x.payload['day_diff'] = torch.clamp(torch.diff(et_day, prepend=et_day[:, :1], dim=1), 0, 14)\n",
    "#         x.payload['day_diff_c'] = torch.clamp(torch.diff(et, prepend=et[:, :1], dim=1) / (60 * 60 * 24), 0, 14)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b57fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c992ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.trx_encoder import TrxEncoder, PaddedBatch\n",
    "from dltranz.seq_encoder.rnn_encoder import RnnEncoder\n",
    "from dltranz.seq_encoder.utils import LastStepEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92667f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca25b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBLinear(torch.nn.Linear):\n",
    "    def forward(self, x: PaddedBatch):\n",
    "        return PaddedBatch(super().forward(x.payload), x.seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lesbian-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedModule(pl.LightningModule):\n",
    "    def __init__(self, params, sampling_strategy_params, loss_params, k,\n",
    "                 lr, weight_decay,\n",
    "                 step_size, gamma,\n",
    "                 base_lr, max_lr, step_size_up, step_size_down,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        t = TrxEncoder(params['trx_seq.trx_encoder'])\n",
    "        print(t.output_size)\n",
    "        self.rnn_enc =  torch.nn.Sequential(\n",
    "            RnnEncoder(params['common_trx_size'], params['rnn']), \n",
    "            LastStepEncoder(),\n",
    "            NormEncoder(),\n",
    "        )\n",
    "        self.seq_encoder_trx_size = params['rnn.hidden_size']\n",
    "        self._seq_encoder_trx = torch.nn.Sequential(\n",
    "            CustomTrxTransform(),\n",
    "            DateFeaturesTransform(),\n",
    "            t, PBLinear(t.output_size, params['common_trx_size']),\n",
    "        )\n",
    "        t = TrxEncoder(params['click_seq.trx_encoder'])\n",
    "        print(t.output_size)\n",
    "        self._seq_encoder_click = torch.nn.Sequential(\n",
    "            CustomClickTransform(),\n",
    "            DateFeaturesTransform(),\n",
    "            t, PBLinear(t.output_size, params['common_trx_size']),\n",
    "        )\n",
    "        \n",
    "        self.cls = torch.nn.Sequential(\n",
    "            L2Scorer(),\n",
    "        )\n",
    "\n",
    "        sampling_strategy = get_sampling_strategy(sampling_strategy_params)\n",
    "        self.loss_fn = get_loss(loss_params, sampling_strategy)\n",
    "        \n",
    "        self.train_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.train_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        self.valid_precision = PrecisionK(k=k, compute_on_step=False)\n",
    "        self.valid_mrr = MeanReciprocalRankK(k=k, compute_on_step=False)\n",
    "        \n",
    "    def seq_encoder_trx(self, x):\n",
    "        x = self._seq_encoder_trx(x)\n",
    "        return self.rnn_enc(x)\n",
    "    \n",
    "    def seq_encoder_click(self, x):\n",
    "        x = self._seq_encoder_click(x)\n",
    "        return self.rnn_enc(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        if self.hparams.step_size is not None:\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optim, step_size=self.hparams.step_size, gamma=self.hparams.gamma)\n",
    "        else:\n",
    "            sheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "                optim,\n",
    "                base_lr=self.hparams.base_lr, max_lr=self.hparams.max_lr,\n",
    "                step_size_up=self.hparams.step_size_up,\n",
    "                step_size_down=self.hparams.step_size_down,\n",
    "                cycle_momentum=False,\n",
    "            )\n",
    "            scheduler = {'scheduler': sheduler, 'interval': 'step'}\n",
    "        return [optim], [scheduler]\n",
    "    \n",
    "#     def forward(self, batch):\n",
    "#         return logits\n",
    "            \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_trx, l_trx, m_trx, x_click, l_click, m_click = batch\n",
    "        \n",
    "        self.log('seq_le/trx_mean', x_trx.seq_lens.float().mean())\n",
    "        self.log('seq_len/click_mean', x_click.seq_lens.float().mean())\n",
    "        \n",
    "        z_trx = self.seq_encoder_trx(x_trx)  # B, H\n",
    "        z_click = self.seq_encoder_click(x_click)  # B, H\n",
    "        \n",
    "        B = z_trx.size(0)\n",
    "        device = z_trx.device\n",
    "        \n",
    "        loss = self.loss_fn(\n",
    "            torch.cat([z_trx, z_click], dim=0),\n",
    "            torch.cat([l_trx, l_click], dim=0),\n",
    "        )\n",
    "        self.log('loss/loss_ml', loss, prog_bar=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = -(z_trx.unsqueeze(1) - z_click.unsqueeze(0)).pow(2).sum(dim=2)\n",
    "            out = out[m_trx == 0][:, m_click == 0]\n",
    "            T, C = out.size()\n",
    "            assert T == C\n",
    "            n_samples = z_trx.size(0) // (l_trx.max().item() + 1)\n",
    "            for i in range(n_samples):\n",
    "                l2 = out[i::n_samples, i::n_samples]\n",
    "                self.train_precision(l2)\n",
    "                self.train_mrr(l2)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, _):\n",
    "        self.log('train_metrics/precision', self.train_precision, prog_bar=True)\n",
    "        self.log('train_metrics/mrr', self.train_mrr, prog_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-conference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "equivalent-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5aff1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    PairedZeroDataset(\n",
    "        pd.concat([df_matching_train, df_matching_test], axis=0)[lambda x: x['rtk'].ne('0')].values,\n",
    "        data=[\n",
    "            dict(chain(features_trx_train.items(), features_trx_test.items())),\n",
    "            dict(chain(features_click_train.items(), features_click_test.items())),\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), RandomSlice(32, 1024)),  # 1024\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), RandomSlice(64, 2048)),  # 2048\n",
    "        ],\n",
    "        n_sample=2,\n",
    "    ),\n",
    "    collate_fn=PairedZeroDataset.collate_fn,\n",
    "    shuffle=True,\n",
    "    num_workers=24,\n",
    "    batch_size=batch_size,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valid_dl_trx = torch.utils.data.DataLoader(\n",
    "    PairedDataset(\n",
    "        np.sort(df_matching_valid['bank'].unique()).reshape(-1, 1), \n",
    "        data=[\n",
    "            features_trx_valid,\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('mcc_code', col_new_cnt='c_cnt'), SeqLenLimit(2000)),  # 2000\n",
    "        ],\n",
    "        n_sample=1,\n",
    "    ),\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=512,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valid_dl_click = torch.utils.data.DataLoader(\n",
    "    PairedDataset(\n",
    "        np.sort(df_matching_valid[lambda x: x['rtk'].ne('0')]['rtk'].unique()).reshape(-1, 1),\n",
    "        data=[\n",
    "            features_click_valid,\n",
    "        ],\n",
    "        augmentations=[\n",
    "            augmentation_chain(DropDuplicate('cat_id', col_new_cnt='c_cnt'), SeqLenLimit(5000)),  # 5000\n",
    "        ],\n",
    "        n_sample=1,\n",
    "    ),\n",
    "    collate_fn=paired_collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    batch_size=512,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "black-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "sup_model = PairedModule(\n",
    "    ConfigFactory.parse_string('''\n",
    "    common_trx_size: 128\n",
    "    rnn: {\n",
    "      type: gru,\n",
    "      hidden_size: 256,\n",
    "      bidir: false,\n",
    "      trainable_starter: static\n",
    "    }\n",
    "    trx_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            mcc_code: {in: 350, out: 64},\n",
    "            currency_rk: {in: 10, out: 4}\n",
    "            hour: {in: 30, out: 16}\n",
    "            # day_diff: {in: 15, out: 8}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            transaction_amt: identity\n",
    "            c_cnt: log\n",
    "          }\n",
    "          was_logified: false\n",
    "          log_scale_factor: 1.0\n",
    "        },\n",
    "    }\n",
    "    click_seq: {\n",
    "        trx_encoder: {\n",
    "          use_batch_norm_with_lens: false\n",
    "          norm_embeddings: false,\n",
    "          embeddings_noise: 0.000,\n",
    "          embeddings: {\n",
    "            cat_id: {in: 400, out: 64},\n",
    "            level_0: {in: 400, out: 16}\n",
    "            level_1: {in: 400, out: 8}\n",
    "            level_2: {in: 400, out: 4}\n",
    "            hour: {in: 30, out: 16}\n",
    "            # day_diff: {in: 15, out: 8}\n",
    "          },\n",
    "          numeric_values: {\n",
    "            c_cnt: log\n",
    "          }\n",
    "          was_logified: false\n",
    "          log_scale_factor: 1.0\n",
    "        },\n",
    "    }\n",
    "'''),                     \n",
    "    sampling_strategy_params=ConfigFactory.parse_string('''\n",
    "        train.sampling_strategy: SemiHardTriplets\n",
    "        # train.balanced: true\n",
    "        # train.neg_count: 10\n",
    "    '''),\n",
    "    loss_params=ConfigFactory.parse_string('''\n",
    "        train.loss: TripletLoss\n",
    "        # train.num_steps: 50\n",
    "        train.margin: 0.5\n",
    "    '''),\n",
    "    k=100 * batch_size // 3000,\n",
    "    lr=0.005, weight_decay=0,\n",
    "    step_size=10 // 10, gamma=0.4 ** (1 / 10),\n",
    "    base_lr=0.0005, max_lr=0.004, step_size_up=300, step_size_down=900,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecological-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(pl.Callback):\n",
    "    def __init__(self, v_trx, v_click, target, device, device_main, k=100, batch_size=1024):\n",
    "        self.v_trx = v_trx\n",
    "        self.v_click = v_click\n",
    "        self.target = target\n",
    "        self.device = device\n",
    "        self.device_main = device_main\n",
    "        self.k = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        was_traning = False\n",
    "        if pl_module.training:\n",
    "            pl_module.eval()\n",
    "            was_traning = True\n",
    "\n",
    "        pl_module.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            z_trx = []\n",
    "            for ((x_trx, _),) in self.v_trx:\n",
    "                z_trx.append(pl_module.seq_encoder_trx(x_trx.to(self.device)))\n",
    "            z_trx = torch.cat(z_trx, dim=0)\n",
    "            z_click = []\n",
    "            for ((x_click, _),) in self.v_click:\n",
    "                z_click.append(pl_module.seq_encoder_click(x_click.to(self.device)))\n",
    "            z_click = torch.cat(z_click, dim=0)\n",
    "\n",
    "            T = z_trx.size(0)\n",
    "            C = z_click.size(0)\n",
    "            device = z_trx.device\n",
    "            ix_t = torch.arange(T, device=device).view(-1, 1).expand(T, C).flatten()\n",
    "            ix_c = torch.arange(C, device=device).view(1, -1).expand(T, C).flatten()\n",
    "\n",
    "            z_out = []\n",
    "            for i in range(0, len(ix_t), self.batch_size):\n",
    "                z_pairs = torch.cat([\n",
    "                    z_trx[ix_t[i:i + self.batch_size]],\n",
    "                    z_click[ix_c[i:i + self.batch_size]],\n",
    "                ], dim=1)\n",
    "                z_out.append(pl_module.cls(z_pairs).unsqueeze(1))\n",
    "            z_out = torch.cat(z_out, dim=0).view(T, C)\n",
    "\n",
    "            precision, mrr, r1 = self.logits_to_metrics(z_out)\n",
    "\n",
    "            pl_module.log('valid_full_metrics/precision', precision, prog_bar=True)\n",
    "            pl_module.log('valid_full_metrics/mrr', mrr, prog_bar=False)\n",
    "            pl_module.log('valid_full_metrics/r1', r1, prog_bar=False)\n",
    "\n",
    "        pl_module.to(self.device_main)\n",
    "        if was_traning:\n",
    "            pl_module.train()\n",
    "\n",
    "    def logits_to_metrics(self, z_out):\n",
    "        T, C = z_out.size()\n",
    "        z_ranks = torch.zeros_like(z_out)\n",
    "        z_ranks[\n",
    "            torch.arange(T, device=self.device).view(-1, 1).expand(T, C),\n",
    "            torch.argsort(z_out, dim=1, descending=True),\n",
    "        ] = torch.arange(C, device=self.device).float().view(1, -1).expand(T, C) + 1\n",
    "        z_ranks = torch.cat([\n",
    "            torch.ones(T, device=self.device).float().view(-1, 1),\n",
    "            z_ranks + 1,\n",
    "        ], dim=1)\n",
    "        \n",
    "        click_uids = np.concatenate([['0'], self.v_click.dataset.pairs[:, 0]])\n",
    "        true_ranks = z_ranks[\n",
    "            np.arange(T),\n",
    "            np.searchsorted(click_uids,\n",
    "                            self.target.set_index('bank')['rtk'].loc[self.v_trx.dataset.pairs[:, 0]].values)\n",
    "        ]\n",
    "        precision = torch.where(true_ranks <= self.k,\n",
    "                                torch.ones(1, device=self.device), torch.zeros(1, device=self.device)).mean()\n",
    "        mrr = torch.where(true_ranks <= self.k, 1 / true_ranks, torch.zeros(1, device=self.device)).mean()\n",
    "        r1 = 2 * mrr * precision / (mrr + precision)\n",
    "        return precision, mrr, r1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "twenty-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[3],\n",
    "    max_steps=3000,\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            every_n_train_steps=1000, save_top_k=-1,\n",
    "        ),\n",
    "        ValidationCallback(valid_dl_trx, valid_dl_click, df_matching_valid,\n",
    "                           torch.device('cuda:2'), torch.device('cuda:3')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "brief-testimony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name               | Type                | Params\n",
      "-----------------------------------------------------------\n",
      "0 | rnn_enc            | Sequential          | 296 K \n",
      "1 | _seq_encoder_trx   | Sequential          | 34.1 K\n",
      "2 | _seq_encoder_click | Sequential          | 51.4 K\n",
      "3 | cls                | Sequential          | 0     \n",
      "4 | train_precision    | PrecisionK          | 0     \n",
      "5 | train_mrr          | MeanReciprocalRankK | 0     \n",
      "6 | valid_precision    | PrecisionK          | 0     \n",
      "7 | valid_mrr          | MeanReciprocalRankK | 0     \n",
      "-----------------------------------------------------------\n",
      "382 K     Trainable params\n",
      "0         Non-trainable params\n",
      "382 K     Total params\n",
      "1.529     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ccdeb78dc446ed8b94e9f6b71e4dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(sup_model, train_dl)  # valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2663d886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0: v0\\n1: v1\\n2: v2\\n3: v3\\n4: v4\\n5: v5\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "0: v0\n",
    "1: v1\n",
    "2: v2\n",
    "3: v3\n",
    "4: v4\n",
    "5: v5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-evanescence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "supreme-subsection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_m = get_scalars('lightning_logs/').set_index('version').loc[[f'version_{i}' for i in [0, 1, 2, 3, 4, 5]]]\n",
    "\n",
    "# df = df_m[lambda x: x['tag'].str.startswith('train_metrics')] \\\n",
    "# .pivot(index='step', columns='tag', values='value')\n",
    "# _, axs = plt.subplots(2, 1, figsize=(16, 15))\n",
    "# for col, ax in zip(df.columns, axs):\n",
    "#     df[col].plot(ax=ax, title=col, grid=True)\n",
    "# plt.show()\n",
    "\n",
    "# df = df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    "# .pivot(index='step', columns='tag', values='value')\n",
    "# _, axs = plt.subplots(3, 1, figsize=(16, 18))\n",
    "# for col, ax in zip(df.columns, axs):\n",
    "#     df[col].plot(ax=ax, title=col, grid=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surgical-amateur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>version</th>\n",
       "      <th>version_0</th>\n",
       "      <th>version_1</th>\n",
       "      <th>version_2</th>\n",
       "      <th>version_3</th>\n",
       "      <th>version_4</th>\n",
       "      <th>version_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>valid_full_metrics/mrr</th>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_full_metrics/precision</th>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_full_metrics/r1</th>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.2686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "version                       version_0  version_1  version_2  version_3  \\\n",
       "tag                                                                        \n",
       "valid_full_metrics/mrr           0.1918     0.1938     0.1938     0.1920   \n",
       "valid_full_metrics/precision     0.4601     0.4601     0.4638     0.4611   \n",
       "valid_full_metrics/r1            0.2708     0.2727     0.2733     0.2711   \n",
       "\n",
       "version                       version_4  version_5  \n",
       "tag                                                 \n",
       "valid_full_metrics/mrr           0.1931     0.1907  \n",
       "valid_full_metrics/precision     0.4720     0.4538  \n",
       "valid_full_metrics/r1            0.2741     0.2686  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    ".pivot_table(index='tag', columns='version', values='value', aggfunc=lambda x: x[-1]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b21b9bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "valid_full_metrics/mrr          0.1925\n",
       "valid_full_metrics/precision    0.4618\n",
       "valid_full_metrics/r1           0.2718\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m[lambda x: x['tag'].str.startswith('valid_full_metrics')] \\\n",
    ".pivot_table(index='tag', columns='version', values='value', aggfunc=lambda x: x[-1]).mean(axis=1).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfee29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtb",
   "language": "python",
   "name": "vtb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
